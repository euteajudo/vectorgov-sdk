{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"VectorGov SDK","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o do VectorGov SDK!</p>"},{"location":"#o-que-e-o-vectorgov","title":"O que \u00e9 o VectorGov?","text":"<p>VectorGov \u00e9 uma plataforma de busca sem\u00e2ntica para documentos jur\u00eddicos brasileiros. Com nosso SDK, voc\u00ea pode:</p> <ul> <li>Buscar informa\u00e7\u00f5es em leis, decretos e instru\u00e7\u00f5es normativas</li> <li>Integrar facilmente com qualquer LLM (OpenAI, Gemini, Claude, etc.)</li> <li>Construir assistentes jur\u00eddicos inteligentes em minutos</li> </ul>"},{"location":"#instalacao","title":"Instala\u00e7\u00e3o","text":"<pre><code>pip install vectorgov\n</code></pre>"},{"location":"#inicio-rapido","title":"In\u00edcio R\u00e1pido","text":"<pre><code>from vectorgov import VectorGov\n\n# Conectar\nvg = VectorGov(api_key=\"vg_sua_chave\")\n\n# Buscar\nresults = vg.search(\"O que \u00e9 ETP?\")\n\n# Usar\nprint(results.to_context())\n</code></pre>"},{"location":"#integracao-com-llms","title":"Integra\u00e7\u00e3o com LLMs","text":"OpenAIGeminiClaude <pre><code>from vectorgov import VectorGov\nfrom openai import OpenAI\n\nvg = VectorGov(api_key=\"vg_xxx\")\nopenai = OpenAI()\n\nresults = vg.search(\"Crit\u00e9rios de julgamento\")\n\nresponse = openai.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=results.to_messages(\"Crit\u00e9rios de julgamento\")\n)\n</code></pre> <pre><code>from vectorgov import VectorGov\nimport google.generativeai as genai\n\nvg = VectorGov(api_key=\"vg_xxx\")\ngenai.configure(api_key=\"...\")\n\nresults = vg.search(\"Crit\u00e9rios de julgamento\")\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\nresponse = model.generate_content(\n    results.to_prompt(\"Crit\u00e9rios de julgamento\")\n)\n</code></pre> <pre><code>from vectorgov import VectorGov\nfrom anthropic import Anthropic\n\nvg = VectorGov(api_key=\"vg_xxx\")\nclient = Anthropic()\n\nresults = vg.search(\"Crit\u00e9rios de julgamento\")\n\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    max_tokens=1024,\n    messages=results.to_messages(\"Crit\u00e9rios de julgamento\")\n)\n</code></pre>"},{"location":"#modos-de-busca","title":"Modos de Busca","text":"Modo Lat\u00eancia Uso <code>fast</code> ~2s Chatbots <code>balanced</code> ~5s Uso geral <code>precise</code> ~15s An\u00e1lises <pre><code>results = vg.search(\"query\", mode=\"precise\")\n</code></pre>"},{"location":"#system-prompts","title":"System Prompts","text":"<p>Controle como o LLM responde suas perguntas:</p> <pre><code># Usar prompt pr\u00e9-definido\nmessages = results.to_messages(\n    query=\"O que \u00e9 ETP?\",\n    system_prompt=vg.get_system_prompt(\"detailed\")\n)\n\n# Ou criar seu pr\u00f3prio\nmessages = results.to_messages(\n    query=\"O que \u00e9 ETP?\",\n    system_prompt=\"Seu prompt personalizado aqui...\"\n)\n\n# Ver prompts dispon\u00edveis\nprint(vg.available_prompts)\n# ['default', 'concise', 'detailed', 'chatbot']\n</code></pre> <p>\ud83d\udcd6 Guia Completo de System Prompts - Conte\u00fado dos prompts, estimativa de tokens e impacto no custo.</p>"},{"location":"#observabilidade-e-auditoria","title":"Observabilidade e Auditoria","text":"<p>Monitore o uso da API, detecte problemas de seguran\u00e7a e atenda requisitos de compliance:</p> <pre><code># Estat\u00edsticas dos \u00faltimos 30 dias\nstats = vg.get_audit_stats(days=30)\nprint(f\"Total eventos: {stats.total_events}\")\nprint(f\"Bloqueados: {stats.blocked_count}\")\n\n# Listar logs de seguran\u00e7a\nlogs = vg.get_audit_logs(severity=\"warning\", limit=50)\nfor log in logs.logs:\n    print(f\"{log.event_type}: {log.action_taken}\")\n</code></pre> <p>\ud83d\udcd6 Guia Completo de Observabilidade e Auditoria - M\u00e9todos, tipos de eventos, exemplos de monitoramento e compliance.</p>"},{"location":"#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>System Prompts - Controle tokens e custos</li> <li>Observabilidade e Auditoria - Monitoramento e compliance</li> <li>Modos de Busca - Detalhes dos modos</li> <li>Integra\u00e7\u00e3o com LLMs - Exemplos avan\u00e7ados</li> </ul>"},{"location":"#suporte","title":"Suporte","text":"<ul> <li>GitHub Issues</li> <li>Email: suporte@vectorgov.io</li> </ul>"},{"location":"llm-reference/","title":"VectorGov SDK - Refer\u00eancia Completa para Desenvolvedores e LLMs","text":"<p>Vers\u00e3o: 0.6.0 | Python: 3.9+ | Licen\u00e7a: MIT</p> <p>Esta documenta\u00e7\u00e3o \u00e9 uma refer\u00eancia completa e autocontida do VectorGov SDK, projetada para ser compartilhada com LLMs (ChatGPT, Claude, Gemini, etc.) para auxiliar no desenvolvimento de aplica\u00e7\u00f5es que utilizam busca sem\u00e2ntica em legisla\u00e7\u00e3o brasileira.</p>"},{"location":"llm-reference/#indice","title":"\u00cdndice","text":"<ul> <li>Vis\u00e3o Geral</li> <li>Instala\u00e7\u00e3o</li> <li>In\u00edcio R\u00e1pido</li> <li>Cliente Principal (VectorGov)</li> <li>Modelos de Dados</li> <li>Modos de Busca</li> <li>Integra\u00e7\u00e3o com LLMs</li> <li>OpenAI GPT</li> <li>Google Gemini</li> <li>Anthropic Claude</li> <li>Modelos Locais (Open-Source)</li> <li>Ollama</li> <li>HuggingFace Transformers</li> <li>Function Calling (Agentes)</li> <li>Frameworks de Agentes</li> <li>LangChain</li> <li>LangGraph</li> <li>Google ADK</li> <li>Servidor MCP</li> <li>Tratamento de Erros</li> <li>System Prompts</li> <li>Refer\u00eancia Completa da API</li> </ul>"},{"location":"llm-reference/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O VectorGov SDK \u00e9 uma biblioteca Python para acessar bases de conhecimento jur\u00eddico brasileiras via busca sem\u00e2ntica. Permite integrar facilmente informa\u00e7\u00f5es de leis, decretos e instru\u00e7\u00f5es normativas em aplica\u00e7\u00f5es de IA.</p>"},{"location":"llm-reference/#principais-funcionalidades","title":"Principais Funcionalidades","text":"Funcionalidade Descri\u00e7\u00e3o Busca Sem\u00e2ntica Encontra informa\u00e7\u00f5es relevantes por significado, n\u00e3o apenas palavras-chave M\u00faltiplos Modos <code>fast</code> (2s), <code>balanced</code> (5s), <code>precise</code> (15s) Integra\u00e7\u00e3o com LLMs Formata\u00e7\u00e3o pronta para OpenAI, Gemini, Claude Function Calling Suporte nativo a ferramentas de agentes Modelos Locais Integra\u00e7\u00e3o com Ollama e Transformers MCP Server Compat\u00edvel com Claude Desktop, Cursor, Windsurf"},{"location":"llm-reference/#documentos-disponiveis-na-base","title":"Documentos Dispon\u00edveis na Base","text":"Documento Tipo Ano Descri\u00e7\u00e3o Lei 14.133 LEI 2021 Nova Lei de Licita\u00e7\u00f5es e Contratos IN SEGES 58 IN 2022 Estudo T\u00e9cnico Preliminar (ETP) IN SEGES 65 IN 2021 Pesquisa de Pre\u00e7os IN SEGES 81 IN 2022 Termo de Refer\u00eancia"},{"location":"llm-reference/#instalacao","title":"Instala\u00e7\u00e3o","text":""},{"location":"llm-reference/#instalacao-basica","title":"Instala\u00e7\u00e3o B\u00e1sica","text":"<pre><code>pip install vectorgov\n</code></pre>"},{"location":"llm-reference/#instalacao-com-extras","title":"Instala\u00e7\u00e3o com Extras","text":"Extra Comando Descri\u00e7\u00e3o LangChain <code>pip install 'vectorgov[langchain]'</code> Retriever e Tool para LangChain LangGraph <code>pip install 'vectorgov[langgraph]'</code> Ferramenta para agentes ReAct Google ADK <code>pip install 'vectorgov[google-adk]'</code> Toolset para Google Agent Dev Kit Transformers <code>pip install 'vectorgov[transformers]'</code> RAG com modelos HuggingFace locais MCP Server <code>pip install 'vectorgov[mcp]'</code> Servidor MCP para Claude Desktop Tudo <code>pip install 'vectorgov[all]'</code> Todas as depend\u00eancias acima"},{"location":"llm-reference/#dependencias-de-llms-separadas","title":"Depend\u00eancias de LLMs (separadas)","text":"<pre><code>pip install openai              # Para OpenAI GPT\npip install google-generativeai # Para Google Gemini\npip install anthropic           # Para Anthropic Claude\n</code></pre> <p>Nota: A integra\u00e7\u00e3o com Ollama n\u00e3o requer depend\u00eancias extras - usa apenas a biblioteca padr\u00e3o do Python.</p>"},{"location":"llm-reference/#inicio-rapido","title":"In\u00edcio R\u00e1pido","text":"<pre><code>from vectorgov import VectorGov\n\n# Inicializar (API key via par\u00e2metro ou vari\u00e1vel VECTORGOV_API_KEY)\nvg = VectorGov(api_key=\"vg_sua_chave_aqui\")\n\n# Buscar informa\u00e7\u00f5es\nresults = vg.search(\"O que \u00e9 o Estudo T\u00e9cnico Preliminar (ETP)?\")\n\n# Exibir resultados\nprint(f\"Total: {results.total}\")\nprint(f\"Lat\u00eancia: {results.latency_ms}ms\")\n\nfor hit in results:\n    print(f\"[{hit.score:.0%}] {hit.source}\")\n    print(hit.text[:200])\n</code></pre>"},{"location":"llm-reference/#saida-esperada","title":"Sa\u00edda Esperada","text":"<pre><code>Total: 5\nLat\u00eancia: 1234ms\n[95%] IN 58/2022, Art. 1\nO Estudo T\u00e9cnico Preliminar - ETP \u00e9 documento constitutivo da primeira etapa...\n</code></pre>"},{"location":"llm-reference/#cliente-principal-vectorgov","title":"Cliente Principal (VectorGov)","text":""},{"location":"llm-reference/#construtor","title":"Construtor","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(\n    api_key=\"vg_xxx\",                          # Obrigat\u00f3rio (ou VECTORGOV_API_KEY)\n    base_url=\"https://vectorgov.io/api/v1\",    # URL da API (padr\u00e3o)\n    timeout=30,                                 # Timeout em segundos\n    default_top_k=5,                           # Resultados padr\u00e3o (1-20)\n    default_mode=\"balanced\",                   # Modo padr\u00e3o\n)\n</code></pre>"},{"location":"llm-reference/#parametros-do-construtor","title":"Par\u00e2metros do Construtor","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>api_key</code> <code>str</code> <code>None</code> Chave de API (formato: <code>vg_*</code>). Usa <code>VECTORGOV_API_KEY</code> se n\u00e3o informada <code>base_url</code> <code>str</code> <code>\"https://vectorgov.io/api/v1\"</code> URL base da API <code>timeout</code> <code>int</code> <code>30</code> Timeout para requisi\u00e7\u00f5es em segundos <code>default_top_k</code> <code>int</code> <code>5</code> Quantidade padr\u00e3o de resultados (1-20) <code>default_mode</code> <code>str\\|SearchMode</code> <code>\"balanced\"</code> Modo de busca padr\u00e3o"},{"location":"llm-reference/#metodo-search","title":"M\u00e9todo search()","text":"<pre><code>results = vg.search(\n    query=\"Quando o ETP pode ser dispensado?\",\n    top_k=5,                    # Quantidade de resultados (1-20)\n    mode=\"balanced\",            # fast, balanced, precise\n    filters={                   # Filtros opcionais\n        \"tipo\": \"in\",           # lei, decreto, in, portaria\n        \"ano\": 2022,            # Ano do documento\n        \"orgao\": \"seges\",       # \u00d3rg\u00e3o emissor\n    },\n)\n</code></pre>"},{"location":"llm-reference/#parametros-do-search","title":"Par\u00e2metros do search()","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>query</code> <code>str</code> - Texto da consulta (3-1000 caracteres) Obrigat\u00f3rio <code>top_k</code> <code>int</code> <code>5</code> Quantidade de resultados (1-20) <code>mode</code> <code>str\\|SearchMode</code> <code>\"balanced\"</code> Modo de busca <code>filters</code> <code>dict</code> <code>None</code> Filtros opcionais"},{"location":"llm-reference/#filtros-disponiveis","title":"Filtros Dispon\u00edveis","text":"Filtro Tipo Valores Exemplo <code>tipo</code> <code>str</code> <code>lei</code>, <code>decreto</code>, <code>in</code>, <code>portaria</code>, <code>resolucao</code> <code>{\"tipo\": \"lei\"}</code> <code>ano</code> <code>int</code> Ano do documento <code>{\"ano\": 2021}</code> <code>orgao</code> <code>str</code> \u00d3rg\u00e3o emissor <code>{\"orgao\": \"seges\"}</code>"},{"location":"llm-reference/#metodo-feedback","title":"M\u00e9todo feedback()","text":"<pre><code># Ap\u00f3s verificar que o resultado foi \u00fatil\nvg.feedback(results.query_id, like=True)\n\n# Se o resultado n\u00e3o foi \u00fatil\nvg.feedback(results.query_id, like=False)\n</code></pre>"},{"location":"llm-reference/#metodo-get_system_prompt","title":"M\u00e9todo get_system_prompt()","text":"<pre><code>prompt = vg.get_system_prompt(\"detailed\")\n# Estilos dispon\u00edveis: 'default', 'concise', 'detailed', 'chatbot'\n</code></pre>"},{"location":"llm-reference/#propriedade-available_prompts","title":"Propriedade available_prompts","text":"<pre><code>print(vg.available_prompts)\n# ['default', 'concise', 'detailed', 'chatbot']\n</code></pre>"},{"location":"llm-reference/#modelos-de-dados","title":"Modelos de Dados","text":""},{"location":"llm-reference/#searchresult","title":"SearchResult","text":"<p>Resultado completo de uma busca.</p> <pre><code>results = vg.search(\"query\")\n\n# Propriedades\nresults.query        # str: Query original\nresults.hits         # list[Hit]: Lista de resultados\nresults.total        # int: Quantidade total\nresults.latency_ms   # int: Tempo de resposta (ms)\nresults.cached       # bool: Se veio do cache\nresults.query_id     # str: ID para feedback\nresults.mode         # str: Modo utilizado\nresults.timestamp    # datetime: Timestamp da busca\n\n# Itera\u00e7\u00e3o\nfor hit in results:\n    print(hit.source)\n\n# Indexa\u00e7\u00e3o\nfirst_hit = results[0]\ncount = len(results)\n</code></pre>"},{"location":"llm-reference/#metodos-do-searchresult","title":"M\u00e9todos do SearchResult","text":""},{"location":"llm-reference/#to_context","title":"to_context()","text":"<p>Converte resultados em string formatada para contexto.</p> <pre><code>context = results.to_context(max_chars=4000)\nprint(context)\n# [1] Lei 14.133/2021, Art. 33\n# Os crit\u00e9rios de julgamento ser\u00e3o...\n#\n# [2] Lei 14.133/2021, Art. 36\n# O julgamento por t\u00e9cnica e pre\u00e7o...\n</code></pre>"},{"location":"llm-reference/#to_messages","title":"to_messages()","text":"<p>Converte para formato de mensagens (OpenAI/Anthropic).</p> <pre><code>messages = results.to_messages(\n    query=\"Crit\u00e9rios de julgamento\",      # Opcional (usa results.query)\n    system_prompt=\"Voc\u00ea \u00e9 um advogado...\", # Opcional\n    max_context_chars=4000,                # Limite de contexto\n)\n# Retorna:\n# [\n#     {\"role\": \"system\", \"content\": \"...\"},\n#     {\"role\": \"user\", \"content\": \"Contexto:\\n...\\n\\nPergunta: ...\"}\n# ]\n</code></pre>"},{"location":"llm-reference/#to_prompt","title":"to_prompt()","text":"<p>Converte para prompt \u00fanico (Gemini e similares).</p> <pre><code>prompt = results.to_prompt(\n    query=\"O que \u00e9 ETP?\",\n    system_prompt=\"...\",\n    max_context_chars=4000,\n)\n# Retorna string \u00fanica com system prompt, contexto e pergunta\n</code></pre>"},{"location":"llm-reference/#to_dict","title":"to_dict()","text":"<p>Converte para dicion\u00e1rio serializ\u00e1vel.</p> <pre><code>data = results.to_dict()\n# {\"query\": \"...\", \"hits\": [...], \"total\": 5, ...}\n</code></pre>"},{"location":"llm-reference/#hit","title":"Hit","text":"<p>Um resultado individual da busca.</p> <pre><code>for hit in results:\n    hit.text         # str: Texto do chunk\n    hit.score        # float: Relev\u00e2ncia (0-1)\n    hit.source       # str: Fonte formatada (\"Lei 14.133/2021, Art. 33\")\n    hit.metadata     # Metadata: Metadados completos\n    hit.chunk_id     # str: ID interno (debug)\n    hit.context      # str: Contexto adicional\n</code></pre>"},{"location":"llm-reference/#metadata","title":"Metadata","text":"<p>Metadados de um documento.</p> <pre><code>meta = hit.metadata\n\nmeta.document_type   # str: Tipo (lei, decreto, in)\nmeta.document_number # str: N\u00famero do documento\nmeta.year            # int: Ano\nmeta.article         # str: N\u00famero do artigo\nmeta.paragraph       # str: N\u00famero do par\u00e1grafo\nmeta.item            # str: N\u00famero do inciso\nmeta.orgao           # str: \u00d3rg\u00e3o emissor\nmeta.extra           # dict: Metadados adicionais\n</code></pre>"},{"location":"llm-reference/#modos-de-busca","title":"Modos de Busca","text":"Modo Lat\u00eancia HyDE Reranker Uso Recomendado <code>fast</code> ~2s \u274c \u274c Chatbots, alta escala <code>balanced</code> ~5s \u274c \u2705 Uso geral (default) <code>precise</code> ~15s \u2705 \u2705 An\u00e1lises cr\u00edticas <pre><code>from vectorgov import SearchMode\n\n# Usando string\nresults = vg.search(\"query\", mode=\"fast\")\n\n# Usando enum\nresults = vg.search(\"query\", mode=SearchMode.PRECISE)\n</code></pre>"},{"location":"llm-reference/#searchmode-enum","title":"SearchMode Enum","text":"<pre><code>from vectorgov import SearchMode\n\nSearchMode.FAST      # \"fast\"\nSearchMode.BALANCED  # \"balanced\"\nSearchMode.PRECISE   # \"precise\"\n</code></pre>"},{"location":"llm-reference/#integracao-com-llms","title":"Integra\u00e7\u00e3o com LLMs","text":""},{"location":"llm-reference/#openai-gpt","title":"OpenAI GPT","text":"<pre><code>from vectorgov import VectorGov\nfrom openai import OpenAI\n\nvg = VectorGov(api_key=\"vg_xxx\")\nopenai_client = OpenAI(api_key=\"sk-xxx\")\n\n# Buscar contexto\nquery = \"Quais os crit\u00e9rios de julgamento na licita\u00e7\u00e3o?\"\nresults = vg.search(query)\n\n# Gerar resposta\nresponse = openai_client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=results.to_messages(query)\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"llm-reference/#google-gemini","title":"Google Gemini","text":"<pre><code>from vectorgov import VectorGov\nimport google.generativeai as genai\n\nvg = VectorGov(api_key=\"vg_xxx\")\ngenai.configure(api_key=\"sua_google_key\")\n\nquery = \"O que \u00e9 ETP?\"\nresults = vg.search(query)\n\n# Monta o prompt\nmessages = results.to_messages(query)\nsystem_prompt = messages[0][\"content\"]\nuser_prompt = messages[1][\"content\"]\n\n# Cria o modelo com system instruction\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.0-flash\",\n    system_instruction=system_prompt\n)\n\nresponse = model.generate_content(user_prompt)\nprint(response.text)\n</code></pre>"},{"location":"llm-reference/#anthropic-claude","title":"Anthropic Claude","text":"<pre><code>from vectorgov import VectorGov\nfrom anthropic import Anthropic\n\nvg = VectorGov(api_key=\"vg_xxx\")\nclient = Anthropic(api_key=\"sk-ant-xxx\")\n\nquery = \"O que \u00e9 ETP?\"\nresults = vg.search(query)\nmessages = results.to_messages(query)\n\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    max_tokens=1024,\n    system=messages[0][\"content\"],  # System prompt separado\n    messages=[{\"role\": \"user\", \"content\": messages[1][\"content\"]}]\n)\n\nprint(response.content[0].text)\n</code></pre>"},{"location":"llm-reference/#modelos-locais-open-source","title":"Modelos Locais (Open-Source)","text":""},{"location":"llm-reference/#ollama","title":"Ollama","text":"<p>Recomendado - Forma mais simples de rodar LLMs localmente. N\u00e3o requer depend\u00eancias extras.</p>"},{"location":"llm-reference/#instalacao-do-ollama","title":"Instala\u00e7\u00e3o do Ollama","text":"<pre><code># 1. Instale o Ollama: https://ollama.ai/\n# 2. Baixe um modelo\nollama pull qwen3:8b\n</code></pre>"},{"location":"llm-reference/#pipeline-rag-simples","title":"Pipeline RAG Simples","text":"<pre><code>from vectorgov import VectorGov\nfrom vectorgov.integrations.ollama import create_rag_pipeline\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\n# Cria pipeline RAG com Ollama\nrag = create_rag_pipeline(vg, model=\"qwen3:8b\")\n\n# Usa como fun\u00e7\u00e3o\nresposta = rag(\"Quais os crit\u00e9rios de julgamento na licita\u00e7\u00e3o?\")\nprint(resposta)\n</code></pre>"},{"location":"llm-reference/#classe-vectorgovollama","title":"Classe VectorGovOllama","text":"<pre><code>from vectorgov import VectorGov\nfrom vectorgov.integrations.ollama import VectorGovOllama, OllamaResponse\n\nvg = VectorGov(api_key=\"vg_xxx\")\nrag = VectorGovOllama(\n    vg,\n    model=\"qwen3:8b\",\n    top_k=5,\n    temperature=0.1,\n    max_tokens=512,\n)\n\nresponse: OllamaResponse = rag.ask(\"O que \u00e9 ETP?\")\n\nprint(response.answer)       # Resposta gerada\nprint(response.sources)      # Lista de fontes\nprint(response.latency_ms)   # Lat\u00eancia total\nprint(response.model)        # Modelo usado\nprint(response.cached)       # Se busca veio do cache\n</code></pre>"},{"location":"llm-reference/#chat-com-historico","title":"Chat com Hist\u00f3rico","text":"<pre><code>messages = [{\"role\": \"user\", \"content\": \"O que \u00e9 ETP?\"}]\n\nresponse = rag.chat(messages, use_rag=True)\nprint(response)\n\n# Continua a conversa\nmessages.append({\"role\": \"assistant\", \"content\": response})\nmessages.append({\"role\": \"user\", \"content\": \"E quando pode ser dispensado?\"})\n\nresponse2 = rag.chat(messages, use_rag=True)\n</code></pre>"},{"location":"llm-reference/#funcoes-auxiliares-do-ollama","title":"Fun\u00e7\u00f5es Auxiliares do Ollama","text":"<pre><code>from vectorgov.integrations.ollama import (\n    check_ollama_available,  # Verifica se Ollama est\u00e1 rodando\n    list_models,             # Lista modelos instalados\n    get_recommended_models,  # Lista modelos recomendados\n    generate,                # Gera\u00e7\u00e3o de baixo n\u00edvel\n)\n\n# Verificar disponibilidade\nif check_ollama_available():\n    models = list_models()\n    print(f\"Modelos: {models}\")\n\n# Modelos recomendados\nfor name, info in get_recommended_models().items():\n    print(f\"{name}: {info['description']} (RAM: {info['ram_gb']}GB)\")\n</code></pre>"},{"location":"llm-reference/#modelos-recomendados-ollama","title":"Modelos Recomendados (Ollama)","text":"Modelo RAM Qualidade Portugu\u00eas Comando <code>qwen2.5:0.5b</code> 1GB B\u00e1sica Bom <code>ollama pull qwen2.5:0.5b</code> <code>qwen2.5:3b</code> 4GB Boa Muito Bom <code>ollama pull qwen2.5:3b</code> <code>qwen2.5:7b</code> 8GB Muito Boa Excelente <code>ollama pull qwen2.5:7b</code> <code>qwen3:8b</code> 8GB Excelente Excelente <code>ollama pull qwen3:8b</code> <code>llama3.2:3b</code> 4GB Boa Bom <code>ollama pull llama3.2:3b</code> <code>mistral:7b</code> 8GB Boa Bom <code>ollama pull mistral:7b</code>"},{"location":"llm-reference/#huggingface-transformers","title":"HuggingFace Transformers","text":"<pre><code>pip install 'vectorgov[transformers]'\n# ou\npip install vectorgov transformers torch accelerate\n</code></pre>"},{"location":"llm-reference/#pipeline-rag-simples_1","title":"Pipeline RAG Simples","text":"<pre><code>from vectorgov import VectorGov\nfrom vectorgov.integrations.transformers import create_rag_pipeline\nfrom transformers import pipeline\n\nvg = VectorGov(api_key=\"vg_xxx\")\nllm = pipeline(\"text-generation\", model=\"Qwen/Qwen2.5-3B-Instruct\", device_map=\"auto\")\n\nrag = create_rag_pipeline(vg, llm, top_k=5, max_new_tokens=512)\n\nresposta = rag(\"Quais os crit\u00e9rios de julgamento na licita\u00e7\u00e3o?\")\nprint(resposta)\n</code></pre>"},{"location":"llm-reference/#classe-vectorgovrag","title":"Classe VectorGovRAG","text":"<pre><code>from vectorgov import VectorGov\nfrom vectorgov.integrations.transformers import VectorGovRAG, RAGResponse\nfrom transformers import pipeline\n\nvg = VectorGov(api_key=\"vg_xxx\")\nllm = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\", device_map=\"auto\")\n\nrag = VectorGovRAG(vg, llm, top_k=5, temperature=0.1)\n\nresponse: RAGResponse = rag.ask(\"O que \u00e9 ETP?\")\n\nprint(response.answer)       # Resposta\nprint(response.sources)      # Fontes\nprint(response.latency_ms)   # Lat\u00eancia de busca\nprint(response.cached)       # Se veio do cache\n</code></pre>"},{"location":"llm-reference/#rodando-sem-gpu-cpu","title":"Rodando sem GPU (CPU)","text":"<pre><code>from transformers import pipeline\nimport torch\n\nllm = pipeline(\n    \"text-generation\",\n    model=\"meta-llama/Llama-3.2-1B-Instruct\",\n    device=\"cpu\",\n    torch_dtype=torch.float32,\n)\n</code></pre>"},{"location":"llm-reference/#modelo-quantizado-4-bit","title":"Modelo Quantizado (4-bit)","text":"<pre><code>from transformers import pipeline, BitsAndBytesConfig\nimport torch\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nllm = pipeline(\n    \"text-generation\",\n    model=\"Qwen/Qwen2.5-7B-Instruct\",\n    model_kwargs={\"quantization_config\": quantization_config},\n    device_map=\"auto\",\n)\n</code></pre>"},{"location":"llm-reference/#modelos-recomendados-huggingface","title":"Modelos Recomendados (HuggingFace)","text":"Modelo VRAM Qualidade Portugu\u00eas <code>meta-llama/Llama-3.2-1B-Instruct</code> 2GB B\u00e1sica Bom <code>Qwen/Qwen2.5-3B-Instruct</code> 6GB Boa Excelente <code>meta-llama/Llama-3.2-3B-Instruct</code> 6GB Boa Bom <code>Qwen/Qwen2.5-7B-Instruct</code> 14GB Muito Boa Excelente <code>microsoft/Phi-3-mini-4k-instruct</code> 4GB Boa Razo\u00e1vel"},{"location":"llm-reference/#function-calling-agentes","title":"Function Calling (Agentes)","text":"<p>O VectorGov pode ser usado como ferramenta em agentes de IA. O LLM decide automaticamente quando consultar a legisla\u00e7\u00e3o.</p>"},{"location":"llm-reference/#openai-function-calling","title":"OpenAI Function Calling","text":"<pre><code>from vectorgov import VectorGov\nfrom openai import OpenAI\n\nvg = VectorGov(api_key=\"vg_xxx\")\nclient = OpenAI()\n\n# Primeira chamada - GPT decide se precisa consultar legisla\u00e7\u00e3o\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Quais os crit\u00e9rios de julgamento?\"}],\n    tools=[vg.to_openai_tool()],  # Registra VectorGov como ferramenta\n    tool_choice=\"auto\",\n)\n\n# Se GPT quiser usar a ferramenta\nif response.choices[0].message.tool_calls:\n    tool_call = response.choices[0].message.tool_calls[0]\n    result = vg.execute_tool_call(tool_call)  # Executa busca\n\n    # Segunda chamada com o resultado\n    final = client.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"user\", \"content\": \"Quais os crit\u00e9rios de julgamento?\"},\n            response.choices[0].message,\n            {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result},\n        ],\n    )\n    print(final.choices[0].message.content)\n</code></pre>"},{"location":"llm-reference/#anthropic-claude-tools","title":"Anthropic Claude Tools","text":"<pre><code>from vectorgov import VectorGov\nfrom anthropic import Anthropic\n\nvg = VectorGov(api_key=\"vg_xxx\")\nclient = Anthropic()\n\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-20250514\",\n    max_tokens=1024,\n    messages=[{\"role\": \"user\", \"content\": \"O que \u00e9 ETP?\"}],\n    tools=[vg.to_anthropic_tool()],\n)\n\n# Processar tool_use se houver\nfor block in response.content:\n    if block.type == \"tool_use\":\n        result = vg.execute_tool_call(block)\n        # Continuar conversa com resultado...\n</code></pre>"},{"location":"llm-reference/#google-gemini-function-calling","title":"Google Gemini Function Calling","text":"<pre><code>from vectorgov import VectorGov\nimport google.generativeai as genai\n\nvg = VectorGov(api_key=\"vg_xxx\")\ngenai.configure(api_key=\"sua_key\")\n\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-2.0-flash\",\n    tools=[vg.to_google_tool()],\n)\n\nresponse = model.generate_content(\"O que \u00e9 ETP?\")\n</code></pre>"},{"location":"llm-reference/#metodos-de-function-calling","title":"M\u00e9todos de Function Calling","text":"M\u00e9todo Descri\u00e7\u00e3o <code>vg.to_openai_tool()</code> Retorna ferramenta no formato OpenAI <code>vg.to_anthropic_tool()</code> Retorna ferramenta no formato Anthropic <code>vg.to_google_tool()</code> Retorna ferramenta no formato Google <code>vg.execute_tool_call(tool_call)</code> Executa tool_call de qualquer provedor"},{"location":"llm-reference/#frameworks-de-agentes","title":"Frameworks de Agentes","text":""},{"location":"llm-reference/#langchain","title":"LangChain","text":"<pre><code>pip install 'vectorgov[langchain]'\n</code></pre>"},{"location":"llm-reference/#vectorgovretriever","title":"VectorGovRetriever","text":"<pre><code>from vectorgov.integrations.langchain import VectorGovRetriever\nfrom langchain.chains import RetrievalQA\nfrom langchain_openai import ChatOpenAI\n\n# Criar retriever\nretriever = VectorGovRetriever(\n    api_key=\"vg_xxx\",\n    top_k=5,\n    mode=\"balanced\",\n    filters={\"tipo\": \"lei\"},  # Filtros padr\u00e3o\n)\n\n# Usar com RetrievalQA\nqa = RetrievalQA.from_chain_type(\n    llm=ChatOpenAI(model=\"gpt-4o-mini\"),\n    retriever=retriever,\n)\n\nanswer = qa.invoke(\"Quando o ETP pode ser dispensado?\")\nprint(answer[\"result\"])\n</code></pre>"},{"location":"llm-reference/#com-lcel-langchain-expression-language","title":"Com LCEL (LangChain Expression Language)","text":"<pre><code>from vectorgov.integrations.langchain import VectorGovRetriever\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import ChatOpenAI\n\nretriever = VectorGovRetriever(api_key=\"vg_xxx\")\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n\nprompt = ChatPromptTemplate.from_template(\"\"\"\nContexto: {context}\n\nPergunta: {question}\n\"\"\")\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\nchain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nanswer = chain.invoke(\"O que \u00e9 ETP?\")\n</code></pre>"},{"location":"llm-reference/#vectorgovtool-para-agentes","title":"VectorGovTool para Agentes","text":"<pre><code>from vectorgov.integrations.langchain import VectorGovTool\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\n\ntool = VectorGovTool(api_key=\"vg_xxx\")\nllm = ChatOpenAI(model=\"gpt-4o\")\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Voc\u00ea \u00e9 um assistente jur\u00eddico.\"),\n    (\"human\", \"{input}\"),\n    (\"placeholder\", \"{agent_scratchpad}\"),\n])\n\nagent = create_openai_tools_agent(llm, [tool], prompt)\nexecutor = AgentExecutor(agent=agent, tools=[tool])\n\nresult = executor.invoke({\"input\": \"O que diz a lei sobre ETP?\"})\n</code></pre>"},{"location":"llm-reference/#langgraph","title":"LangGraph","text":"<pre><code>pip install 'vectorgov[langgraph]'\n</code></pre>"},{"location":"llm-reference/#react-agent","title":"ReAct Agent","text":"<pre><code>from vectorgov.integrations.langgraph import create_vectorgov_tool\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_openai import ChatOpenAI\n\n# Criar ferramenta VectorGov\ntool = create_vectorgov_tool(api_key=\"vg_xxx\", top_k=5)\n\n# Criar agente ReAct\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\nagent = create_react_agent(llm, tools=[tool])\n\n# Executar\nresult = agent.invoke({\"messages\": [(\"user\", \"O que \u00e9 ETP?\")]})\nprint(result[\"messages\"][-1].content)\n</code></pre>"},{"location":"llm-reference/#grafo-rag-customizado","title":"Grafo RAG Customizado","text":"<pre><code>from vectorgov.integrations.langgraph import create_retrieval_node, VectorGovState\nfrom langgraph.graph import StateGraph, START, END\nfrom langchain_openai import ChatOpenAI\n\n# N\u00f3 de retrieval VectorGov\nretrieval_node = create_retrieval_node(api_key=\"vg_xxx\", top_k=5)\n\n# N\u00f3 de gera\u00e7\u00e3o\ndef generate(state: VectorGovState) -&gt; dict:\n    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n    context = state.get(\"context\", \"\")\n    query = state.get(\"query\", \"\")\n    response = llm.invoke(f\"Contexto: {context}\\n\\nPergunta: {query}\")\n    return {\"response\": response.content}\n\n# Construir grafo\nbuilder = StateGraph(dict)\nbuilder.add_node(\"retrieve\", retrieval_node)\nbuilder.add_node(\"generate\", generate)\nbuilder.add_edge(START, \"retrieve\")\nbuilder.add_edge(\"retrieve\", \"generate\")\nbuilder.add_edge(\"generate\", END)\n\ngraph = builder.compile()\n\n# Executar\nresult = graph.invoke({\"query\": \"Quando o ETP pode ser dispensado?\"})\nprint(result[\"response\"])\n</code></pre>"},{"location":"llm-reference/#grafo-rag-pre-configurado","title":"Grafo RAG Pr\u00e9-configurado","text":"<pre><code>from vectorgov.integrations.langgraph import create_legal_rag_graph\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\ngraph = create_legal_rag_graph(llm=llm, api_key=\"vg_xxx\")\n\nresult = graph.invoke({\"query\": \"Quais os crit\u00e9rios de julgamento?\"})\nprint(result[\"response\"])\n</code></pre>"},{"location":"llm-reference/#vectorgovstate","title":"VectorGovState","text":"<pre><code>from vectorgov.integrations.langgraph import VectorGovState\nfrom typing import TypedDict, Annotated, Sequence\nfrom langchain_core.messages import BaseMessage\nimport operator\n\nclass VectorGovState(TypedDict, total=False):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    query: str\n    documents: list\n    context: str\n    sources: list[str]\n</code></pre>"},{"location":"llm-reference/#google-adk","title":"Google ADK","text":"<pre><code>pip install 'vectorgov[google-adk]'\n</code></pre>"},{"location":"llm-reference/#ferramenta-de-busca","title":"Ferramenta de Busca","text":"<pre><code>from vectorgov.integrations.google_adk import create_search_tool\n\n# Criar ferramenta\nsearch = create_search_tool(api_key=\"vg_xxx\", top_k=5)\n\n# Testar diretamente (sem agente)\nresult = search(\"O que \u00e9 ETP?\")\nprint(result)\n</code></pre>"},{"location":"llm-reference/#toolset-completo","title":"Toolset Completo","text":"<pre><code>from vectorgov.integrations.google_adk import VectorGovToolset\n\ntoolset = VectorGovToolset(api_key=\"vg_xxx\")\n\n# Lista ferramentas dispon\u00edveis\nfor tool in toolset.get_tools():\n    print(f\"- {tool.__name__}\")\n# - search_brazilian_legislation\n# - list_available_documents\n# - get_article_text\n\n# Usar com agente ADK\nfrom google.adk.agents import Agent\n\nagent = Agent(\n    name=\"legal_assistant\",\n    model=\"gemini-2.0-flash\",\n    tools=toolset.get_tools(),\n)\n</code></pre>"},{"location":"llm-reference/#agente-adk-pre-configurado","title":"Agente ADK Pr\u00e9-configurado","text":"<pre><code>from vectorgov.integrations.google_adk import create_legal_agent\n\nagent = create_legal_agent(api_key=\"vg_xxx\")\nresponse = agent.run(\"Quais os crit\u00e9rios de julgamento na licita\u00e7\u00e3o?\")\nprint(response)\n</code></pre>"},{"location":"llm-reference/#servidor-mcp","title":"Servidor MCP","text":"<p>O VectorGov pode funcionar como servidor MCP (Model Context Protocol), permitindo integra\u00e7\u00e3o direta com Claude Desktop, Cursor, Windsurf e outras ferramentas compat\u00edveis.</p> <pre><code>pip install 'vectorgov[mcp]'\n</code></pre>"},{"location":"llm-reference/#configuracao-no-claude-desktop","title":"Configura\u00e7\u00e3o no Claude Desktop","text":"<p>Adicione ao arquivo <code>claude_desktop_config.json</code>:</p> <p>Windows: <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> macOS: <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></p> <pre><code>{\n    \"mcpServers\": {\n        \"vectorgov\": {\n            \"command\": \"uvx\",\n            \"args\": [\"vectorgov-mcp\"],\n            \"env\": {\n                \"VECTORGOV_API_KEY\": \"vg_sua_chave_aqui\"\n            }\n        }\n    }\n}\n</code></pre> <p>Ou se instalou via pip:</p> <pre><code>{\n    \"mcpServers\": {\n        \"vectorgov\": {\n            \"command\": \"vectorgov-mcp\",\n            \"env\": {\n                \"VECTORGOV_API_KEY\": \"vg_sua_chave_aqui\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"llm-reference/#executar-manualmente","title":"Executar Manualmente","text":"<pre><code># Via uvx (sem instalar)\nuvx vectorgov-mcp\n\n# Via pip (ap\u00f3s instalar)\nvectorgov-mcp\n\n# Via Python\npython -m vectorgov.mcp\n</code></pre>"},{"location":"llm-reference/#ferramentas-mcp-disponiveis","title":"Ferramentas MCP Dispon\u00edveis","text":"Ferramenta Descri\u00e7\u00e3o <code>search_legislation</code> Busca sem\u00e2ntica em legisla\u00e7\u00e3o brasileira <code>list_available_documents</code> Lista documentos dispon\u00edveis na base <code>get_article_text</code> Obt\u00e9m texto completo de um artigo espec\u00edfico"},{"location":"llm-reference/#tratamento-de-erros","title":"Tratamento de Erros","text":""},{"location":"llm-reference/#excecoes-disponiveis","title":"Exce\u00e7\u00f5es Dispon\u00edveis","text":"<pre><code>from vectorgov import (\n    VectorGovError,      # Exce\u00e7\u00e3o base\n    AuthError,           # API key inv\u00e1lida/expirada (401)\n    RateLimitError,      # Rate limit excedido (429)\n    ValidationError,     # Par\u00e2metros inv\u00e1lidos (400)\n    ServerError,         # Erro interno do servidor (500)\n    ConnectionError,     # Erro de conex\u00e3o\n    TimeoutError,        # Timeout na requisi\u00e7\u00e3o\n)\n</code></pre>"},{"location":"llm-reference/#exemplo-de-tratamento","title":"Exemplo de Tratamento","text":"<pre><code>from vectorgov import (\n    VectorGov,\n    VectorGovError,\n    AuthError,\n    RateLimitError,\n    ValidationError,\n)\n\ntry:\n    results = vg.search(\"query\")\nexcept AuthError:\n    print(\"API key inv\u00e1lida ou expirada\")\nexcept RateLimitError as e:\n    print(f\"Rate limit. Tente em {e.retry_after}s\")\nexcept ValidationError as e:\n    print(f\"Erro no campo {e.field}: {e.message}\")\nexcept VectorGovError as e:\n    print(f\"Erro: {e.message}\")\n</code></pre>"},{"location":"llm-reference/#atributos-das-excecoes","title":"Atributos das Exce\u00e7\u00f5es","text":"Exce\u00e7\u00e3o Atributos <code>VectorGovError</code> <code>message</code>, <code>status_code</code>, <code>response</code> <code>AuthError</code> <code>message</code> (status_code=401) <code>RateLimitError</code> <code>message</code>, <code>retry_after</code> (status_code=429) <code>ValidationError</code> <code>message</code>, <code>field</code> (status_code=400)"},{"location":"llm-reference/#system-prompts","title":"System Prompts","text":""},{"location":"llm-reference/#prompts-pre-definidos","title":"Prompts Pr\u00e9-definidos","text":"Estilo Descri\u00e7\u00e3o <code>default</code> Balanceado, formal, cita fontes <code>concise</code> Respostas curtas e diretas <code>detailed</code> An\u00e1lise profunda, estruturada <code>chatbot</code> Tom amig\u00e1vel, acess\u00edvel"},{"location":"llm-reference/#uso-de-prompts","title":"Uso de Prompts","text":"<pre><code># Usar prompt pr\u00e9-definido\nresults = vg.search(\"query\")\nmessages = results.to_messages(\n    system_prompt=vg.get_system_prompt(\"detailed\")\n)\n\n# Listar prompts dispon\u00edveis\nprint(vg.available_prompts)\n# ['default', 'concise', 'detailed', 'chatbot']\n\n# Prompt totalmente customizado\ncustom_prompt = \"\"\"Voc\u00ea \u00e9 um advogado especialista em licita\u00e7\u00f5es.\nResponda de forma t\u00e9cnica e cite artigos espec\u00edficos.\"\"\"\n\nmessages = results.to_messages(system_prompt=custom_prompt)\n</code></pre>"},{"location":"llm-reference/#conteudo-dos-prompts","title":"Conte\u00fado dos Prompts","text":""},{"location":"llm-reference/#default","title":"default","text":"<pre><code>Voc\u00ea \u00e9 um assistente especializado em legisla\u00e7\u00e3o brasileira, especialmente em licita\u00e7\u00f5es e contratos p\u00fablicos.\n\nInstru\u00e7\u00f5es:\n1. Use APENAS as informa\u00e7\u00f5es do contexto fornecido para responder\n2. Se a informa\u00e7\u00e3o n\u00e3o estiver no contexto, diga que n\u00e3o encontrou\n3. Sempre cite as fontes usando o formato [Fonte: Lei X, Art. Y]\n4. Seja objetivo e direto nas respostas\n5. Use linguagem formal adequada ao contexto jur\u00eddico\n</code></pre>"},{"location":"llm-reference/#concise","title":"concise","text":"<pre><code>Voc\u00ea \u00e9 um assistente jur\u00eddico. Responda de forma concisa e direta usando apenas o contexto fornecido. Cite as fontes.\n</code></pre>"},{"location":"llm-reference/#detailed","title":"detailed","text":"<pre><code>Voc\u00ea \u00e9 um especialista em direito administrativo brasileiro.\n\nAo responder:\n1. Analise cuidadosamente todo o contexto fornecido\n2. Estruture a resposta em t\u00f3picos quando apropriado\n3. Cite TODAS as fontes relevantes no formato [Lei X/Ano, Art. Y, \u00a7Z]\n4. Explique termos t\u00e9cnicos quando necess\u00e1rio\n5. Se houver diverg\u00eancias ou exce\u00e7\u00f5es, mencione-as\n6. Conclua com um resumo pr\u00e1tico quando aplic\u00e1vel\n\nUse SOMENTE informa\u00e7\u00f5es do contexto. N\u00e3o invente ou extrapole.\n</code></pre>"},{"location":"llm-reference/#chatbot","title":"chatbot","text":"<pre><code>Voc\u00ea \u00e9 um assistente virtual amig\u00e1vel especializado em licita\u00e7\u00f5es p\u00fablicas.\nResponda de forma clara e acess\u00edvel, evitando jarg\u00e3o excessivo.\nBaseie suas respostas apenas no contexto fornecido e cite as fontes.\n</code></pre>"},{"location":"llm-reference/#referencia-completa-da-api","title":"Refer\u00eancia Completa da API","text":""},{"location":"llm-reference/#exports-do-modulo-principal","title":"Exports do M\u00f3dulo Principal","text":"<pre><code>from vectorgov import (\n    # Cliente principal\n    VectorGov,\n\n    # Modelos\n    SearchResult,\n    Hit,\n    Metadata,\n\n    # Configura\u00e7\u00e3o\n    SearchMode,\n    SYSTEM_PROMPTS,\n\n    # Exce\u00e7\u00f5es\n    VectorGovError,\n    AuthError,\n    RateLimitError,\n    ValidationError,\n    ServerError,\n    ConnectionError,\n    TimeoutError,\n\n    # Formatters\n    to_langchain_docs,\n    to_llamaindex_nodes,\n    format_citations,\n    create_rag_prompt,\n)\n</code></pre>"},{"location":"llm-reference/#integracoes-disponiveis","title":"Integra\u00e7\u00f5es Dispon\u00edveis","text":"M\u00f3dulo Exports Requisitos <code>vectorgov.integrations.langchain</code> <code>VectorGovRetriever</code>, <code>VectorGovTool</code>, <code>to_langchain_documents</code> <code>langchain</code>, <code>langchain-core</code> <code>vectorgov.integrations.langgraph</code> <code>VectorGovState</code>, <code>create_vectorgov_tool</code>, <code>create_retrieval_node</code>, <code>create_legal_rag_graph</code> <code>langgraph</code>, <code>langchain-core</code> <code>vectorgov.integrations.google_adk</code> <code>create_search_tool</code>, <code>create_list_documents_tool</code>, <code>create_get_article_tool</code>, <code>VectorGovToolset</code>, <code>create_legal_agent</code> <code>google-adk</code> <code>vectorgov.integrations.ollama</code> <code>create_rag_pipeline</code>, <code>VectorGovOllama</code>, <code>OllamaResponse</code>, <code>check_ollama_available</code>, <code>list_models</code>, <code>generate</code>, <code>get_recommended_models</code> Nenhum (usa urllib) <code>vectorgov.integrations.transformers</code> <code>create_rag_pipeline</code>, <code>VectorGovRAG</code>, <code>RAGResponse</code>, <code>format_prompt_for_transformers</code>, <code>get_recommended_models</code>, <code>estimate_vram_usage</code> <code>transformers</code>, <code>torch</code>, <code>accelerate</code> <code>vectorgov.mcp</code> <code>create_server</code>, <code>run_server</code>, <code>main</code> <code>mcp</code>"},{"location":"llm-reference/#variaveis-de-ambiente","title":"Vari\u00e1veis de Ambiente","text":"Vari\u00e1vel Descri\u00e7\u00e3o <code>VECTORGOV_API_KEY</code> Chave de API (formato: <code>vg_*</code>) <pre><code># Definir via ambiente\nexport VECTORGOV_API_KEY=vg_sua_chave_aqui\n</code></pre> <pre><code># Usa automaticamente a vari\u00e1vel de ambiente\nvg = VectorGov()  # N\u00e3o precisa passar api_key\n</code></pre>"},{"location":"llm-reference/#exemplos-completos","title":"Exemplos Completos","text":""},{"location":"llm-reference/#chatbot-com-historico-ollama","title":"Chatbot com Hist\u00f3rico (Ollama)","text":"<pre><code>from vectorgov import VectorGov\nfrom vectorgov.integrations.ollama import VectorGovOllama\n\nvg = VectorGov(api_key=\"vg_xxx\")\nrag = VectorGovOllama(vg, model=\"qwen3:8b\")\n\nmessages = []\n\nwhile True:\n    user_input = input(\"Voc\u00ea: \")\n    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n        break\n\n    messages.append({\"role\": \"user\", \"content\": user_input})\n    response = rag.chat(messages, use_rag=True)\n    messages.append({\"role\": \"assistant\", \"content\": response})\n\n    print(f\"Assistente: {response}\")\n</code></pre>"},{"location":"llm-reference/#api-rest-com-fastapi","title":"API REST com FastAPI","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom vectorgov import VectorGov, VectorGovError\n\napp = FastAPI()\nvg = VectorGov()\n\nclass Query(BaseModel):\n    question: str\n    top_k: int = 5\n    mode: str = \"balanced\"\n\n@app.post(\"/search\")\nasync def search(query: Query):\n    try:\n        results = vg.search(\n            query=query.question,\n            top_k=query.top_k,\n            mode=query.mode,\n        )\n        return results.to_dict()\n    except VectorGovError as e:\n        raise HTTPException(status_code=e.status_code or 500, detail=e.message)\n</code></pre>"},{"location":"llm-reference/#pipeline-rag-com-streaming-openai","title":"Pipeline RAG com Streaming (OpenAI)","text":"<pre><code>from vectorgov import VectorGov\nfrom openai import OpenAI\n\nvg = VectorGov(api_key=\"vg_xxx\")\nclient = OpenAI()\n\nquery = \"O que \u00e9 ETP?\"\nresults = vg.search(query)\n\nstream = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=results.to_messages(query),\n    stream=True,\n)\n\nfor chunk in stream:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n</code></pre>"},{"location":"llm-reference/#changelog-resumido","title":"Changelog Resumido","text":"Vers\u00e3o Data Principais Mudan\u00e7as 0.6.0 2025-01-08 Integra\u00e7\u00e3o Ollama (RAG local sem depend\u00eancias) 0.5.0 2025-01-08 Integra\u00e7\u00e3o HuggingFace Transformers 0.4.0 2025-01-08 LangGraph + Google ADK 0.3.0 2025-01-08 Servidor MCP 0.2.0 2025-01-08 Function Calling + LangChain 0.1.0 2025-01-07 Release inicial"},{"location":"llm-reference/#suporte","title":"Suporte","text":"<ul> <li>GitHub Issues: https://github.com/euteajudo/vectorgov-sdk/issues</li> <li>Email: suporte@vectorgov.io</li> <li>Documenta\u00e7\u00e3o: https://docs.vectorgov.io</li> <li>Playground: https://vectorgov.io/playground</li> </ul>"},{"location":"llm-reference/#licenca","title":"Licen\u00e7a","text":"<p>MIT License - veja LICENSE para detalhes.</p> <p>\u00daltima atualiza\u00e7\u00e3o: Janeiro 2025 | Vers\u00e3o do SDK: 0.6.0</p>"},{"location":"api/client/","title":"Cliente VectorGov","text":"<p>A classe principal para interagir com a API VectorGov.</p>"},{"location":"api/client/#inicializacao","title":"Inicializa\u00e7\u00e3o","text":"<pre><code>from vectorgov import VectorGov\n\n# B\u00e1sico\nvg = VectorGov(api_key=\"vg_xxx\")\n\n# Com configura\u00e7\u00f5es\nvg = VectorGov(\n    api_key=\"vg_xxx\",\n    base_url=\"https://vectorgov.io/api/v1\",\n    timeout=30,\n    default_top_k=5,\n    default_mode=\"balanced\",\n)\n</code></pre>"},{"location":"api/client/#parametros","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>api_key</code> <code>str</code> <code>None</code> Chave de API. Usa <code>VECTORGOV_API_KEY</code> se n\u00e3o informada <code>base_url</code> <code>str</code> <code>\"https://vectorgov.io/api/v1\"</code> URL base da API <code>timeout</code> <code>int</code> <code>30</code> Timeout em segundos <code>default_top_k</code> <code>int</code> <code>5</code> Quantidade padr\u00e3o de resultados <code>default_mode</code> <code>str</code> <code>\"balanced\"</code> Modo de busca padr\u00e3o"},{"location":"api/client/#metodos","title":"M\u00e9todos","text":""},{"location":"api/client/#search","title":"search()","text":"<p>Busca informa\u00e7\u00f5es na base de conhecimento.</p> <pre><code>results = vg.search(\n    query=\"O que \u00e9 ETP?\",\n    top_k=5,\n    mode=\"balanced\",\n    filters={\"tipo\": \"lei\", \"ano\": 2021},\n)\n</code></pre>"},{"location":"api/client/#parametros_1","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>query</code> <code>str</code> - Texto da consulta (obrigat\u00f3rio) <code>top_k</code> <code>int</code> <code>5</code> Quantidade de resultados (1-20) <code>mode</code> <code>str</code> <code>\"balanced\"</code> Modo: <code>fast</code>, <code>balanced</code>, <code>precise</code> <code>filters</code> <code>dict</code> <code>None</code> Filtros opcionais"},{"location":"api/client/#filtros-disponiveis","title":"Filtros Dispon\u00edveis","text":"Filtro Tipo Exemplo Descri\u00e7\u00e3o <code>tipo</code> <code>str</code> <code>\"lei\"</code> Tipo do documento <code>ano</code> <code>int</code> <code>2021</code> Ano do documento <code>orgao</code> <code>str</code> <code>\"seges\"</code> \u00d3rg\u00e3o emissor"},{"location":"api/client/#retorno","title":"Retorno","text":"<p>Retorna um objeto <code>SearchResult</code>.</p>"},{"location":"api/client/#feedback","title":"feedback()","text":"<p>Envia feedback sobre um resultado de busca.</p> <pre><code>vg.feedback(results.query_id, like=True)\n</code></pre>"},{"location":"api/client/#parametros_2","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Descri\u00e7\u00e3o <code>query_id</code> <code>str</code> ID da query (de <code>results.query_id</code>) <code>like</code> <code>bool</code> <code>True</code> para positivo, <code>False</code> para negativo"},{"location":"api/client/#retorno_1","title":"Retorno","text":"<p><code>True</code> se o feedback foi registrado com sucesso.</p>"},{"location":"api/client/#get_system_prompt","title":"get_system_prompt()","text":"<p>Retorna um system prompt pr\u00e9-definido.</p> <pre><code>prompt = vg.get_system_prompt(\"detailed\")\n</code></pre>"},{"location":"api/client/#parametros_3","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>style</code> <code>str</code> <code>\"default\"</code> Estilo do prompt"},{"location":"api/client/#estilos-disponiveis","title":"Estilos Dispon\u00edveis","text":"Estilo Descri\u00e7\u00e3o <code>default</code> Balanceado, formal, cita fontes <code>concise</code> Respostas curtas e diretas <code>detailed</code> An\u00e1lise profunda, estruturada <code>chatbot</code> Tom amig\u00e1vel, acess\u00edvel"},{"location":"api/client/#available_prompts","title":"available_prompts","text":"<p>Propriedade que lista os estilos de prompt dispon\u00edveis.</p> <pre><code>print(vg.available_prompts)\n# ['default', 'concise', 'detailed', 'chatbot']\n</code></pre>"},{"location":"api/client/#exemplo-completo","title":"Exemplo Completo","text":"<pre><code>from vectorgov import VectorGov\n\n# Inicializar\nvg = VectorGov(api_key=\"vg_xxx\")\n\n# Buscar\nresults = vg.search(\n    \"Quando o ETP pode ser dispensado?\",\n    mode=\"precise\",\n    top_k=5,\n    filters={\"tipo\": \"in\"},\n)\n\n# Usar resultados\nprint(f\"Total: {results.total}\")\nprint(f\"Lat\u00eancia: {results.latency_ms}ms\")\n\nfor hit in results:\n    print(f\"- {hit.source}: {hit.text[:100]}...\")\n\n# Feedback\nvg.feedback(results.query_id, like=True)\n</code></pre>"},{"location":"api/models/","title":"Modelos","text":"<p>Classes de dados retornadas pela API.</p>"},{"location":"api/models/#searchresult","title":"SearchResult","text":"<p>Resultado completo de uma busca.</p>"},{"location":"api/models/#propriedades","title":"Propriedades","text":"Propriedade Tipo Descri\u00e7\u00e3o <code>query</code> <code>str</code> Query original <code>hits</code> <code>list[Hit]</code> Lista de resultados <code>total</code> <code>int</code> Quantidade total <code>latency_ms</code> <code>int</code> Tempo de resposta (ms) <code>cached</code> <code>bool</code> Se veio do cache <code>query_id</code> <code>str</code> ID para feedback <code>mode</code> <code>str</code> Modo utilizado <code>timestamp</code> <code>datetime</code> Timestamp da busca"},{"location":"api/models/#metodos","title":"M\u00e9todos","text":""},{"location":"api/models/#to_context","title":"to_context()","text":"<p>Converte os resultados em uma string de contexto.</p> <pre><code>context = results.to_context(max_chars=4000)\n</code></pre> <p>Par\u00e2metros:</p> Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>max_chars</code> <code>int</code> <code>None</code> Limite de caracteres <p>Retorno:</p> <pre><code>[1] Lei 14.133/2021, Art. 33\nOs crit\u00e9rios de julgamento ser\u00e3o...\n\n[2] Lei 14.133/2021, Art. 36\nO julgamento por t\u00e9cnica e pre\u00e7o...\n</code></pre>"},{"location":"api/models/#to_messages","title":"to_messages()","text":"<p>Converte para formato de mensagens (OpenAI/Claude).</p> <pre><code>messages = results.to_messages(\n    query=\"Crit\u00e9rios de julgamento\",\n    system_prompt=\"Voc\u00ea \u00e9 um assistente jur\u00eddico...\",\n    max_context_chars=4000,\n)\n</code></pre> <p>Par\u00e2metros:</p> Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>query</code> <code>str</code> <code>self.query</code> Pergunta <code>system_prompt</code> <code>str</code> Prompt padr\u00e3o System prompt <code>max_context_chars</code> <code>int</code> <code>None</code> Limite de contexto <p>Retorno:</p> <pre><code>[\n    {\"role\": \"system\", \"content\": \"...\"},\n    {\"role\": \"user\", \"content\": \"Contexto:\\n...\\n\\nPergunta: ...\"}\n]\n</code></pre>"},{"location":"api/models/#to_prompt","title":"to_prompt()","text":"<p>Converte para um prompt \u00fanico (Gemini).</p> <pre><code>prompt = results.to_prompt(\n    query=\"Crit\u00e9rios de julgamento\",\n    system_prompt=\"...\",\n)\n</code></pre> <p>Par\u00e2metros: Mesmos de <code>to_messages()</code>.</p> <p>Retorno: String \u00fanica com system prompt, contexto e pergunta.</p>"},{"location":"api/models/#to_dict","title":"to_dict()","text":"<p>Converte para dicion\u00e1rio.</p> <pre><code>data = results.to_dict()\n</code></pre>"},{"location":"api/models/#iteracao","title":"Itera\u00e7\u00e3o","text":"<p><code>SearchResult</code> suporta itera\u00e7\u00e3o e indexa\u00e7\u00e3o:</p> <pre><code># Iterar\nfor hit in results:\n    print(hit.source)\n\n# Indexar\nfirst = results[0]\n\n# Quantidade\nprint(len(results))\n</code></pre>"},{"location":"api/models/#hit","title":"Hit","text":"<p>Um resultado individual da busca.</p>"},{"location":"api/models/#propriedades_1","title":"Propriedades","text":"Propriedade Tipo Descri\u00e7\u00e3o <code>text</code> <code>str</code> Texto do chunk <code>score</code> <code>float</code> Relev\u00e2ncia (0-1) <code>source</code> <code>str</code> Fonte formatada <code>metadata</code> <code>Metadata</code> Metadados completos <code>chunk_id</code> <code>str</code> ID interno (debug) <code>context</code> <code>str</code> Contexto adicional"},{"location":"api/models/#exemplo","title":"Exemplo","text":"<pre><code>for hit in results:\n    print(f\"Fonte: {hit.source}\")\n    print(f\"Score: {hit.score:.2%}\")\n    print(f\"Texto: {hit.text[:200]}...\")\n    print(f\"Tipo: {hit.metadata.document_type}\")\n</code></pre>"},{"location":"api/models/#metadata","title":"Metadata","text":"<p>Metadados de um documento.</p>"},{"location":"api/models/#propriedades_2","title":"Propriedades","text":"Propriedade Tipo Descri\u00e7\u00e3o <code>document_type</code> <code>str</code> Tipo (lei, decreto, in) <code>document_number</code> <code>str</code> N\u00famero do documento <code>year</code> <code>int</code> Ano <code>article</code> <code>str</code> N\u00famero do artigo <code>paragraph</code> <code>str</code> N\u00famero do par\u00e1grafo <code>item</code> <code>str</code> N\u00famero do inciso <code>orgao</code> <code>str</code> \u00d3rg\u00e3o emissor <code>extra</code> <code>dict</code> Metadados adicionais"},{"location":"api/models/#exemplo_1","title":"Exemplo","text":"<pre><code>meta = hit.metadata\n\nprint(f\"Documento: {meta.document_type} {meta.document_number}/{meta.year}\")\nprint(f\"Artigo: {meta.article}\")\nprint(f\"\u00d3rg\u00e3o: {meta.orgao}\")\n</code></pre>"},{"location":"api/models/#searchmode","title":"SearchMode","text":"<p>Enum com os modos de busca dispon\u00edveis.</p> <pre><code>from vectorgov import SearchMode\n\n# Usar enum\nresults = vg.search(\"query\", mode=SearchMode.PRECISE)\n\n# Ou string\nresults = vg.search(\"query\", mode=\"precise\")\n</code></pre>"},{"location":"api/models/#valores","title":"Valores","text":"Valor Descri\u00e7\u00e3o <code>SearchMode.FAST</code> Mais r\u00e1pido (~2s) <code>SearchMode.BALANCED</code> Balanceado (~5s) <code>SearchMode.PRECISE</code> Mais preciso (~15s)"},{"location":"guides/observability-audit/","title":"Observabilidade e Auditoria","text":"<p>Monitore, rastreie e analise o uso da sua integra\u00e7\u00e3o com VectorGov</p> <p>O VectorGov SDK oferece ferramentas completas de observabilidade e auditoria, permitindo que voc\u00ea monitore o uso da API, detecte problemas de seguran\u00e7a, atenda requisitos de compliance e debug de integra\u00e7\u00f5es.</p>"},{"location":"guides/observability-audit/#seguranca-e-isolamento-de-dados","title":"Seguran\u00e7a e Isolamento de Dados","text":""},{"location":"guides/observability-audit/#por-que-seus-logs-sao-privados","title":"Por que seus logs s\u00e3o privados?","text":"<p>O VectorGov \u00e9 uma plataforma multi-tenant, onde m\u00faltiplos clientes compartilham a mesma infraestrutura. Para garantir privacidade e seguran\u00e7a:</p> Aspecto Como Funciona Isolamento Cada API Key s\u00f3 acessa seus pr\u00f3prios logs Filtro Autom\u00e1tico O backend filtra por <code>api_key_id</code> automaticamente Sem Acesso Cruzado Imposs\u00edvel ver logs de outras organiza\u00e7\u00f5es Dados Sens\u00edveis Queries podem conter informa\u00e7\u00f5es confidenciais"},{"location":"guides/observability-audit/#o-que-isso-significa-para-voce","title":"O que isso significa para voc\u00ea?","text":"<pre><code>from vectorgov import VectorGov\n\n# Empresa A\nvg_a = VectorGov(api_key=\"vg_empresa_a_xxx\")\nlogs_a = vg_a.get_audit_logs()  # S\u00f3 v\u00ea logs da Empresa A\n\n# Empresa B\nvg_b = VectorGov(api_key=\"vg_empresa_b_yyy\")\nlogs_b = vg_b.get_audit_logs()  # S\u00f3 v\u00ea logs da Empresa B\n\n# N\u00e3o h\u00e1 como a Empresa A acessar logs da Empresa B\n</code></pre>"},{"location":"guides/observability-audit/#por-que-usar-auditoria","title":"Por que usar Auditoria?","text":"Caso de Uso Descri\u00e7\u00e3o Compliance Atenda requisitos de LGPD, auditoria interna e governan\u00e7a Seguran\u00e7a Detecte tentativas de inje\u00e7\u00e3o, vazamento de PII e uso suspeito Debugging Investigue problemas de integra\u00e7\u00e3o e erros de valida\u00e7\u00e3o Monitoramento Acompanhe m\u00e9tricas de uso, lat\u00eancia e padr\u00f5es de queries Billing Entenda o consumo da API para planejamento de custos"},{"location":"guides/observability-audit/#metodos-disponiveis","title":"M\u00e9todos Dispon\u00edveis","text":"<p>O SDK oferece 3 m\u00e9todos para acessar dados de auditoria:</p> M\u00e9todo Fun\u00e7\u00e3o Retorno <code>get_audit_logs()</code> Lista eventos de auditoria com filtros <code>AuditLogsResponse</code> <code>get_audit_stats()</code> Estat\u00edsticas agregadas de um per\u00edodo <code>AuditStats</code> <code>get_audit_event_types()</code> Lista tipos de eventos dispon\u00edveis <code>list[str]</code> <p>IMPORTANTE: Voc\u00ea s\u00f3 tem acesso aos seus pr\u00f3prios logs de auditoria. Logs de outros clientes n\u00e3o s\u00e3o vis\u00edveis.</p>"},{"location":"guides/observability-audit/#importancia-de-cada-metodo","title":"Import\u00e2ncia de Cada M\u00e9todo","text":""},{"location":"guides/observability-audit/#get_audit_logs-investigacao-e-compliance","title":"<code>get_audit_logs()</code> - Investiga\u00e7\u00e3o e Compliance","text":"<p>Por que \u00e9 importante:</p> Cen\u00e1rio Como o M\u00e9todo Ajuda Investiga\u00e7\u00e3o de Incidentes Veja exatamente o que aconteceu, quando e qual query causou o problema Compliance LGPD Prove que dados pessoais foram detectados e tratados adequadamente Debugging Identifique queries mal formadas ou que causam erros de valida\u00e7\u00e3o Auditoria Interna Documente uso da API para relat\u00f3rios de governan\u00e7a <p>O que cada campo retornado significa:</p> Campo Significado A\u00e7\u00e3o Recomendada <code>event_type</code> Tipo do evento (ex: <code>pii_detected</code>) Filtre por tipos cr\u00edticos <code>severity</code> Gravidade (<code>info</code>, <code>warning</code>, <code>critical</code>) Monitore <code>critical</code> em tempo real <code>risk_score</code> Score de risco de 0.0 a 1.0 Investigue scores &gt; 0.7 <code>action_taken</code> O que o sistema fez (<code>logged</code>, <code>blocked</code>, <code>warned</code>) Revise a\u00e7\u00f5es <code>blocked</code> <code>query_text</code> Query que gerou o evento (truncada) Use para reproduzir problemas <code>detection_types</code> O que foi detectado (ex: <code>[\"cpf\", \"email\"]</code>) Identifique padr\u00f5es de PII"},{"location":"guides/observability-audit/#get_audit_stats-visao-gerencial-e-tendencias","title":"<code>get_audit_stats()</code> - Vis\u00e3o Gerencial e Tend\u00eancias","text":"<p>Por que \u00e9 importante:</p> Cen\u00e1rio Como o M\u00e9todo Ajuda Dashboard Executivo Mostre m\u00e9tricas de seguran\u00e7a para stakeholders Identifica\u00e7\u00e3o de Tend\u00eancias Detecte aumento de tentativas de injection Planejamento de Capacidade Entenda volume de uso para sizing KPIs de Seguran\u00e7a Acompanhe taxa de bloqueios vs requisi\u00e7\u00f5es totais <p>M\u00e9tricas chave retornadas:</p> Campo Significado Meta Ideal <code>total_events</code> Total de eventos no per\u00edodo Crescimento controlado <code>blocked_count</code> Requisi\u00e7\u00f5es bloqueadas Pr\u00f3ximo de 0 <code>warning_count</code> Avisos gerados Monitorar tend\u00eancia <code>events_by_type</code> Distribui\u00e7\u00e3o por tipo Maioria deve ser <code>search_completed</code> <code>events_by_severity</code> Distribui\u00e7\u00e3o por gravidade Maioria deve ser <code>info</code>"},{"location":"guides/observability-audit/#get_audit_event_types-descoberta-e-integracao","title":"<code>get_audit_event_types()</code> - Descoberta e Integra\u00e7\u00e3o","text":"<p>Por que \u00e9 importante:</p> Cen\u00e1rio Como o M\u00e9todo Ajuda Construir Interfaces Popular dropdowns de filtro dinamicamente Manter Compatibilidade Descobrir novos tipos de eventos adicionados Documenta\u00e7\u00e3o Gerar docs autom\u00e1ticos dos eventos poss\u00edveis Valida\u00e7\u00e3o Verificar se um tipo de evento existe antes de filtrar"},{"location":"guides/observability-audit/#get_audit_logs-listar-eventos","title":"<code>get_audit_logs()</code> - Listar Eventos","text":"<p>Lista eventos de auditoria com filtros avan\u00e7ados e pagina\u00e7\u00e3o.</p>"},{"location":"guides/observability-audit/#parametros","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>limit</code> <code>int</code> <code>50</code> Quantidade por p\u00e1gina (1-100) <code>page</code> <code>int</code> <code>1</code> P\u00e1gina de resultados <code>severity</code> <code>str</code> <code>None</code> Filtrar por severidade <code>event_type</code> <code>str</code> <code>None</code> Filtrar por tipo de evento <code>event_category</code> <code>str</code> <code>None</code> Filtrar por categoria <code>start_date</code> <code>str</code> <code>None</code> Data inicial (ISO 8601) <code>end_date</code> <code>str</code> <code>None</code> Data final (ISO 8601)"},{"location":"guides/observability-audit/#exemplo-basico","title":"Exemplo B\u00e1sico","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\n# Listar \u00faltimos 50 logs\nlogs = vg.get_audit_logs()\nprint(f\"Total de eventos: {logs.total}\")\n\nfor log in logs.logs:\n    print(f\"{log.created_at} | {log.event_type} | {log.severity}\")\n</code></pre>"},{"location":"guides/observability-audit/#exemplo-com-filtros","title":"Exemplo com Filtros","text":"<pre><code># Apenas eventos de seguran\u00e7a com severidade warning ou critical\nlogs = vg.get_audit_logs(\n    event_category=\"security\",\n    severity=\"warning\",\n    limit=100,\n)\n\nfor log in logs.logs:\n    print(f\"\u26a0\ufe0f {log.event_type}: {log.query_text[:50] if log.query_text else 'N/A'}...\")\n    if log.action_taken:\n        print(f\"   A\u00e7\u00e3o: {log.action_taken}\")\n</code></pre>"},{"location":"guides/observability-audit/#exemplo-com-periodo","title":"Exemplo com Per\u00edodo","text":"<pre><code># Eventos da \u00faltima semana\nlogs = vg.get_audit_logs(\n    start_date=\"2025-01-12\",\n    end_date=\"2025-01-19\",\n    limit=100,\n)\n\nprint(f\"Eventos na semana: {logs.total}\")\n</code></pre>"},{"location":"guides/observability-audit/#get_audit_stats-estatisticas-agregadas","title":"<code>get_audit_stats()</code> - Estat\u00edsticas Agregadas","text":"<p>Obt\u00e9m estat\u00edsticas resumidas de um per\u00edodo, ideal para dashboards e monitoramento.</p>"},{"location":"guides/observability-audit/#parametros_1","title":"Par\u00e2metros","text":"Par\u00e2metro Tipo Padr\u00e3o Descri\u00e7\u00e3o <code>days</code> <code>int</code> <code>30</code> Per\u00edodo em dias (1-90)"},{"location":"guides/observability-audit/#exemplo","title":"Exemplo","text":"<pre><code># Estat\u00edsticas dos \u00faltimos 30 dias\nstats = vg.get_audit_stats(days=30)\n\nprint(f\"\ud83d\udcca Resumo dos \u00faltimos {stats.period_days} dias:\")\nprint(f\"   Total de eventos: {stats.total_events}\")\nprint(f\"   Bloqueados: {stats.blocked_count}\")\nprint(f\"   Avisos: {stats.warning_count}\")\n\nprint(f\"\\n\ud83d\udcc8 Por tipo:\")\nfor event_type, count in stats.events_by_type.items():\n    print(f\"   {event_type}: {count}\")\n\nprint(f\"\\n\ud83d\udea8 Por severidade:\")\nfor severity, count in stats.events_by_severity.items():\n    print(f\"   {severity}: {count}\")\n</code></pre>"},{"location":"guides/observability-audit/#saida-exemplo","title":"Sa\u00edda Exemplo","text":"<pre><code>\ud83d\udcca Resumo dos \u00faltimos 30 dias:\n   Total de eventos: 1234\n   Bloqueados: 12\n   Avisos: 45\n\n\ud83d\udcc8 Por tipo:\n   search_completed: 1150\n   pii_detected: 32\n   injection_detected: 7\n   rate_limit_exceeded: 45\n\n\ud83d\udea8 Por severidade:\n   info: 1150\n   warning: 72\n   critical: 12\n</code></pre>"},{"location":"guides/observability-audit/#get_audit_event_types-tipos-de-eventos","title":"<code>get_audit_event_types()</code> - Tipos de Eventos","text":"<p>Lista todos os tipos de eventos de auditoria dispon\u00edveis no sistema.</p>"},{"location":"guides/observability-audit/#exemplo_1","title":"Exemplo","text":"<pre><code>types = vg.get_audit_event_types()\nprint(\"Tipos de eventos dispon\u00edveis:\")\nfor event_type in types:\n    print(f\"  - {event_type}\")\n</code></pre>"},{"location":"guides/observability-audit/#tipos-de-eventos","title":"Tipos de Eventos","text":"Tipo Categoria Descri\u00e7\u00e3o <code>pii_detected</code> security Dados pessoais (CPF, email, telefone) detectados na query <code>injection_detected</code> security Tentativa de prompt injection detectada <code>injection_blocked</code> security Tentativa de prompt injection bloqueada <code>rate_limit_exceeded</code> performance Rate limit da API excedido <code>auth_failed</code> security Falha de autentica\u00e7\u00e3o (API key inv\u00e1lida) <code>validation_error</code> validation Erro de valida\u00e7\u00e3o de par\u00e2metros <code>low_relevance_query</code> performance Query com baixa relev\u00e2ncia nos resultados <code>search_completed</code> performance Busca conclu\u00edda com sucesso <code>feedback_received</code> performance Feedback (like/dislike) recebido"},{"location":"guides/observability-audit/#severidades","title":"Severidades","text":"Severidade Descri\u00e7\u00e3o A\u00e7\u00e3o do Sistema <code>info</code> Informativo Apenas registrado <code>warning</code> Aviso Registrado com alerta <code>critical</code> Cr\u00edtico Requisi\u00e7\u00e3o pode ser bloqueada"},{"location":"guides/observability-audit/#categorias","title":"Categorias","text":"Categoria Eventos T\u00edpicos <code>security</code> pii_detected, injection_detected, auth_failed <code>performance</code> rate_limit_exceeded, search_completed, low_relevance_query <code>validation</code> validation_error"},{"location":"guides/observability-audit/#modelos-de-dados","title":"Modelos de Dados","text":""},{"location":"guides/observability-audit/#auditlog","title":"<code>AuditLog</code>","text":"<p>Representa um evento individual de auditoria.</p> <pre><code>@dataclass\nclass AuditLog:\n    id: str                    # ID \u00fanico do evento\n    event_type: str            # Tipo do evento\n    event_category: str        # Categoria (security, performance, validation)\n    severity: str              # Severidade (info, warning, critical)\n    query_text: str | None     # Query que gerou o evento\n    detection_types: list[str] # Tipos de detec\u00e7\u00e3o ativados\n    risk_score: float | None   # Score de risco (0.0 a 1.0)\n    action_taken: str | None   # A\u00e7\u00e3o tomada (logged, blocked, warned)\n    endpoint: str | None       # Endpoint que gerou o evento\n    client_ip: str | None      # IP do cliente (anonimizado)\n    created_at: str | None     # Data/hora (ISO 8601)\n    details: dict              # Detalhes adicionais\n</code></pre>"},{"location":"guides/observability-audit/#auditlogsresponse","title":"<code>AuditLogsResponse</code>","text":"<p>Resposta paginada de listagem de logs.</p> <pre><code>@dataclass\nclass AuditLogsResponse:\n    logs: list[AuditLog]  # Lista de logs\n    total: int            # Total de logs encontrados\n    page: int             # P\u00e1gina atual\n    pages: int            # Total de p\u00e1ginas\n    limit: int            # Limite por p\u00e1gina\n</code></pre>"},{"location":"guides/observability-audit/#auditstats","title":"<code>AuditStats</code>","text":"<p>Estat\u00edsticas agregadas de auditoria.</p> <pre><code>@dataclass\nclass AuditStats:\n    total_events: int        # Total de eventos no per\u00edodo\n    events_by_type: dict     # Contagem por tipo\n    events_by_severity: dict # Contagem por severidade\n    events_by_category: dict # Contagem por categoria\n    blocked_count: int       # Quantidade bloqueada\n    warning_count: int       # Quantidade de avisos\n    period_days: int         # Per\u00edodo em dias\n</code></pre>"},{"location":"guides/observability-audit/#casos-de-uso-praticos","title":"Casos de Uso Pr\u00e1ticos","text":""},{"location":"guides/observability-audit/#1-dashboard-de-monitoramento","title":"1. Dashboard de Monitoramento","text":"<pre><code>from vectorgov import VectorGov\nfrom datetime import datetime\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\ndef gerar_relatorio_diario():\n    \"\"\"Gera relat\u00f3rio di\u00e1rio de uso da API.\"\"\"\n    stats = vg.get_audit_stats(days=1)\n\n    print(f\"=== Relat\u00f3rio {datetime.now().strftime('%Y-%m-%d')} ===\")\n    print(f\"Total de requisi\u00e7\u00f5es: {stats.total_events}\")\n    print(f\"Problemas de seguran\u00e7a: {stats.blocked_count + stats.warning_count}\")\n\n    # Taxa de sucesso\n    total = stats.total_events\n    problemas = stats.blocked_count + stats.warning_count\n    taxa_sucesso = ((total - problemas) / total * 100) if total &gt; 0 else 100\n    print(f\"Taxa de sucesso: {taxa_sucesso:.1f}%\")\n\n    return stats\n\n# Executar diariamente via cron/scheduler\nrelatorio = gerar_relatorio_diario()\n</code></pre>"},{"location":"guides/observability-audit/#2-alertas-de-seguranca","title":"2. Alertas de Seguran\u00e7a","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\ndef verificar_alertas_seguranca():\n    \"\"\"Verifica eventos cr\u00edticos de seguran\u00e7a.\"\"\"\n    logs = vg.get_audit_logs(\n        event_category=\"security\",\n        severity=\"critical\",\n        limit=10,\n    )\n\n    if logs.total &gt; 0:\n        print(f\"\ud83d\udea8 ALERTA: {logs.total} eventos cr\u00edticos de seguran\u00e7a!\")\n        for log in logs.logs:\n            print(f\"  - {log.event_type}: {log.query_text[:50] if log.query_text else 'N/A'}...\")\n            print(f\"    Risk Score: {log.risk_score}\")\n            print(f\"    A\u00e7\u00e3o: {log.action_taken}\")\n        return True\n\n    print(\"\u2705 Nenhum evento cr\u00edtico de seguran\u00e7a\")\n    return False\n\n# Verificar periodicamente\nverificar_alertas_seguranca()\n</code></pre>"},{"location":"guides/observability-audit/#3-analise-de-pii-lgpd","title":"3. An\u00e1lise de PII (LGPD)","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\ndef relatorio_pii(dias: int = 30):\n    \"\"\"Relat\u00f3rio de detec\u00e7\u00f5es de PII para compliance LGPD.\"\"\"\n    logs = vg.get_audit_logs(\n        event_type=\"pii_detected\",\n        limit=100,\n    )\n\n    stats = vg.get_audit_stats(days=dias)\n    pii_count = stats.events_by_type.get(\"pii_detected\", 0)\n\n    print(f\"=== Relat\u00f3rio LGPD ({dias} dias) ===\")\n    print(f\"Detec\u00e7\u00f5es de PII: {pii_count}\")\n\n    if logs.logs:\n        print(\"\\n\u00daltimas detec\u00e7\u00f5es:\")\n        for log in logs.logs[:5]:\n            print(f\"  - {log.created_at}: {log.details.get('pii_types', [])}\")\n\n    return pii_count\n\n# Executar mensalmente para compliance\nrelatorio_pii(dias=30)\n</code></pre>"},{"location":"guides/observability-audit/#4-debug-de-integracao","title":"4. Debug de Integra\u00e7\u00e3o","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\ndef investigar_erros(dias: int = 7):\n    \"\"\"Investiga erros de valida\u00e7\u00e3o para debug.\"\"\"\n    logs = vg.get_audit_logs(\n        event_category=\"validation\",\n        limit=50,\n    )\n\n    if logs.total == 0:\n        print(\"\u2705 Nenhum erro de valida\u00e7\u00e3o encontrado\")\n        return\n\n    print(f\"\u26a0\ufe0f {logs.total} erros de valida\u00e7\u00e3o:\")\n\n    # Agrupa por tipo\n    erros_por_tipo = {}\n    for log in logs.logs:\n        tipo = log.details.get(\"field\", \"unknown\")\n        erros_por_tipo[tipo] = erros_por_tipo.get(tipo, 0) + 1\n\n    print(\"\\nErros por campo:\")\n    for campo, count in sorted(erros_por_tipo.items(), key=lambda x: -x[1]):\n        print(f\"  {campo}: {count}\")\n\ninvestigar_erros()\n</code></pre>"},{"location":"guides/observability-audit/#5-monitoramento-de-rate-limit","title":"5. Monitoramento de Rate Limit","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\ndef monitorar_rate_limit():\n    \"\"\"Monitora consumo de rate limit.\"\"\"\n    stats = vg.get_audit_stats(days=1)\n\n    rate_limit_hits = stats.events_by_type.get(\"rate_limit_exceeded\", 0)\n    total_requests = stats.total_events\n\n    if rate_limit_hits &gt; 0:\n        percentual = (rate_limit_hits / total_requests * 100) if total_requests &gt; 0 else 0\n        print(f\"\u26a0\ufe0f Rate limit atingido {rate_limit_hits}x ({percentual:.1f}% das requisi\u00e7\u00f5es)\")\n        print(\"   Considere aumentar seu limite ou otimizar o uso da API\")\n    else:\n        print(\"\u2705 Rate limit: dentro do limite\")\n\n    return rate_limit_hits\n\nmonitorar_rate_limit()\n</code></pre>"},{"location":"guides/observability-audit/#boas-praticas","title":"Boas Pr\u00e1ticas","text":""},{"location":"guides/observability-audit/#faca","title":"\u2705 Fa\u00e7a","text":"<ol> <li>Monitore regularmente - Configure verifica\u00e7\u00f5es di\u00e1rias de eventos cr\u00edticos</li> <li>Armazene logs localmente - Para an\u00e1lises hist\u00f3ricas al\u00e9m do per\u00edodo dispon\u00edvel na API</li> <li>Configure alertas - Para eventos de seguran\u00e7a com severidade <code>warning</code> ou <code>critical</code></li> <li>Documente investiga\u00e7\u00f5es - Mantenha registro de incidentes e a\u00e7\u00f5es tomadas</li> </ol>"},{"location":"guides/observability-audit/#evite","title":"\u274c Evite","text":"<ol> <li>Ignorar avisos de seguran\u00e7a - Eventos <code>warning</code> podem indicar problemas crescentes</li> <li>Expor logs em interfaces p\u00fablicas - Logs podem conter informa\u00e7\u00f5es sens\u00edveis</li> <li>Polling excessivo - Use intervalos razo\u00e1veis (ex: a cada 5 minutos)</li> <li>Descartar logs sem an\u00e1lise - Revise padr\u00f5es antes de arquivar</li> </ol>"},{"location":"guides/observability-audit/#integracao-com-ferramentas-externas","title":"Integra\u00e7\u00e3o com Ferramentas Externas","text":""},{"location":"guides/observability-audit/#exportar-para-json","title":"Exportar para JSON","text":"<pre><code>import json\nfrom vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\nlogs = vg.get_audit_logs(limit=100)\n\n# Exportar para arquivo\nwith open(\"audit_logs.json\", \"w\") as f:\n    json.dump([{\n        \"id\": log.id,\n        \"event_type\": log.event_type,\n        \"severity\": log.severity,\n        \"created_at\": log.created_at,\n        \"query_text\": log.query_text,\n        \"details\": log.details,\n    } for log in logs.logs], f, indent=2)\n</code></pre>"},{"location":"guides/observability-audit/#enviar-para-slack","title":"Enviar para Slack","text":"<pre><code>import requests\nfrom vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\nSLACK_WEBHOOK = \"https://hooks.slack.com/services/xxx\"\n\ndef alertar_slack():\n    logs = vg.get_audit_logs(severity=\"critical\", limit=5)\n\n    if logs.total &gt; 0:\n        message = f\"\ud83d\udea8 *{logs.total} eventos cr\u00edticos no VectorGov*\\n\"\n        for log in logs.logs:\n            message += f\"\u2022 `{log.event_type}`: {log.action_taken}\\n\"\n\n        requests.post(SLACK_WEBHOOK, json={\"text\": message})\n</code></pre>"},{"location":"guides/observability-audit/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>System Prompts - Controle tokens e custos</li> <li>Refer\u00eancia da API - Documenta\u00e7\u00e3o t\u00e9cnica completa</li> <li>Modelos - Todos os modelos de dados</li> </ul>"},{"location":"guides/system-prompts/","title":"System Prompts - Guia Completo","text":"<p>Controle total sobre como o LLM responde suas perguntas</p> <p>O VectorGov SDK oferece prompts pr\u00e9-definidos otimizados para diferentes casos de uso, mas voc\u00ea tamb\u00e9m pode criar seus pr\u00f3prios prompts personalizados para ter controle total sobre tokens e custos.</p>"},{"location":"guides/system-prompts/#como-funciona","title":"Como Funciona","text":"<p>Quando voc\u00ea usa <code>to_messages()</code>, o SDK combina:</p> <ol> <li>System Prompt \u2192 Instru\u00e7\u00f5es para o LLM (voc\u00ea controla)</li> <li>Contexto \u2192 Documentos relevantes da busca (VectorGov fornece)</li> <li>Pergunta do usu\u00e1rio \u2192 Sua query</li> </ol> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    COMPOSI\u00c7\u00c3O DA MENSAGEM                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  System Prompt (voc\u00ea escolhe)     ~50-130 tokens                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500               \u2502\n\u2502  \"Voc\u00ea \u00e9 um assistente especializado...\"                        \u2502\n\u2502                                                                 \u2502\n\u2502  +                                                              \u2502\n\u2502                                                                 \u2502\n\u2502  Contexto (VectorGov)             ~500-2000 tokens              \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500               \u2502\n\u2502  \"Art. 5\u00ba O estudo t\u00e9cnico preliminar...\"                       \u2502\n\u2502  \"Art. 14 O ETP poder\u00e1 ser dispensado...\"                       \u2502\n\u2502                                                                 \u2502\n\u2502  +                                                              \u2502\n\u2502                                                                 \u2502\n\u2502  Pergunta do usu\u00e1rio              ~10-50 tokens                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500               \u2502\n\u2502  \"O que \u00e9 ETP e quando pode ser dispensado?\"                    \u2502\n\u2502                                                                 \u2502\n\u2502  =                                                              \u2502\n\u2502                                                                 \u2502\n\u2502  TOTAL INPUT                      ~560-2180 tokens              \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/system-prompts/#prompts-pre-definidos","title":"Prompts Pr\u00e9-definidos","text":"<p>O SDK inclui 4 prompts otimizados. Use <code>vg.available_prompts</code> para listar e <code>vg.get_system_prompt(\"nome\")</code> para obter o conte\u00fado.</p>"},{"location":"guides/system-prompts/#1-default-uso-geral","title":"1. <code>default</code> - Uso Geral","text":"<p>Tokens: ~95 tokens | Caracteres: 340</p> <pre><code>Voc\u00ea \u00e9 um assistente especializado em legisla\u00e7\u00e3o brasileira, especialmente em licita\u00e7\u00f5es e contratos p\u00fablicos.\n\nInstru\u00e7\u00f5es:\n1. Use APENAS as informa\u00e7\u00f5es do contexto fornecido para responder\n2. Se a informa\u00e7\u00e3o n\u00e3o estiver no contexto, diga que n\u00e3o encontrou\n3. Sempre cite as fontes usando o formato [Fonte: Lei X, Art. Y]\n4. Seja objetivo e direto nas respostas\n5. Use linguagem formal adequada ao contexto jur\u00eddico\n</code></pre> <p>Quando usar: Consultas gerais, documenta\u00e7\u00e3o, relat\u00f3rios internos.</p>"},{"location":"guides/system-prompts/#2-concise-respostas-curtas","title":"2. <code>concise</code> - Respostas Curtas","text":"<p>Tokens: ~40 tokens | Caracteres: 130</p> <pre><code>Voc\u00ea \u00e9 um assistente jur\u00eddico. Responda de forma concisa e direta usando apenas o contexto fornecido. Cite as fontes.\n</code></pre> <p>Quando usar: Chatbots, respostas r\u00e1pidas, alto volume de requisi\u00e7\u00f5es.</p> <p>Economia: ~55 tokens a menos que <code>default</code> por requisi\u00e7\u00e3o.</p>"},{"location":"guides/system-prompts/#3-detailed-analises-completas","title":"3. <code>detailed</code> - An\u00e1lises Completas","text":"<p>Tokens: ~120 tokens | Caracteres: 430</p> <pre><code>Voc\u00ea \u00e9 um especialista em direito administrativo brasileiro.\n\nAo responder:\n1. Analise cuidadosamente todo o contexto fornecido\n2. Estruture a resposta em t\u00f3picos quando apropriado\n3. Cite TODAS as fontes relevantes no formato [Lei X/Ano, Art. Y, \u00a7Z]\n4. Explique termos t\u00e9cnicos quando necess\u00e1rio\n5. Se houver diverg\u00eancias ou exce\u00e7\u00f5es, mencione-as\n6. Conclua com um resumo pr\u00e1tico quando aplic\u00e1vel\n\nUse SOMENTE informa\u00e7\u00f5es do contexto. N\u00e3o invente ou extrapole.\n</code></pre> <p>Quando usar: Pareceres, an\u00e1lises jur\u00eddicas, due diligence.</p> <p>Custo extra: ~25 tokens a mais que <code>default</code>.</p>"},{"location":"guides/system-prompts/#4-chatbot-linguagem-acessivel","title":"4. <code>chatbot</code> - Linguagem Acess\u00edvel","text":"<p>Tokens: ~60 tokens | Caracteres: 200</p> <pre><code>Voc\u00ea \u00e9 um assistente virtual amig\u00e1vel especializado em licita\u00e7\u00f5es p\u00fablicas.\nResponda de forma clara e acess\u00edvel, evitando jarg\u00e3o excessivo.\nBaseie suas respostas apenas no contexto fornecido e cite as fontes.\n</code></pre> <p>Quando usar: Atendimento ao p\u00fablico, portais de transpar\u00eancia, FAQs.</p>"},{"location":"guides/system-prompts/#comparativo-de-tokens","title":"Comparativo de Tokens","text":"Prompt Tokens vs Default Melhor Para <code>concise</code> ~40 -55 tokens Chatbots, alto volume <code>chatbot</code> ~60 -35 tokens Atendimento p\u00fablico <code>default</code> ~95 baseline Uso geral <code>detailed</code> ~120 +25 tokens An\u00e1lises jur\u00eddicas"},{"location":"guides/system-prompts/#impacto-no-custo-por-llm","title":"Impacto no Custo por LLM","text":""},{"location":"guides/system-prompts/#custo-do-system-prompt-apenas","title":"Custo do System Prompt (apenas)","text":"<p>Considerando pre\u00e7os de Janeiro/2025:</p> LLM Pre\u00e7o Input <code>concise</code> <code>default</code> <code>detailed</code> GPT-4o $2.50/1M $0.0001 $0.00024 $0.0003 GPT-4o-mini $0.15/1M $0.000006 $0.000014 $0.000018 Claude Sonnet $3.00/1M $0.00012 $0.000285 $0.00036 Gemini 1.5 Flash $0.075/1M $0.000003 $0.0000071 $0.000009"},{"location":"guides/system-prompts/#custo-total-estimado-por-requisicao","title":"Custo Total Estimado por Requisi\u00e7\u00e3o","text":"<p>Considerando: System Prompt + Contexto (~1000 tokens) + Pergunta (~30 tokens) + Resposta (~500 tokens output)</p> LLM <code>concise</code> <code>default</code> <code>detailed</code> Economia concise\u2192detailed GPT-4o $0.0077 $0.0078 $0.0079 ~$0.20/1000 req GPT-4o-mini $0.00046 $0.00047 $0.00048 ~$0.02/1000 req Claude Sonnet $0.0107 $0.0108 $0.0109 ~$0.20/1000 req Gemini 1.5 Flash $0.00023 $0.00023 $0.00024 ~$0.01/1000 req <p>Conclus\u00e3o: O system prompt representa ~5-10% do custo total. O maior impacto vem do contexto (chunks retornados) e da resposta gerada.</p>"},{"location":"guides/system-prompts/#estimativa-de-custos-em-escala","title":"Estimativa de Custos em Escala","text":""},{"location":"guides/system-prompts/#10000-requisicoesmes","title":"10.000 requisi\u00e7\u00f5es/m\u00eas","text":"LLM Prompt <code>concise</code> Prompt <code>detailed</code> GPT-4o ~$77/m\u00eas ~$79/m\u00eas GPT-4o-mini ~$4.60/m\u00eas ~$4.80/m\u00eas Claude Sonnet ~$107/m\u00eas ~$109/m\u00eas Gemini 1.5 Flash ~$2.30/m\u00eas ~$2.40/m\u00eas"},{"location":"guides/system-prompts/#100000-requisicoesmes","title":"100.000 requisi\u00e7\u00f5es/m\u00eas","text":"LLM Prompt <code>concise</code> Prompt <code>detailed</code> GPT-4o ~$770/m\u00eas ~$790/m\u00eas GPT-4o-mini ~$46/m\u00eas ~$48/m\u00eas Claude Sonnet ~$1,070/m\u00eas ~$1,090/m\u00eas Gemini 1.5 Flash ~$23/m\u00eas ~$24/m\u00eas"},{"location":"guides/system-prompts/#criando-prompts-personalizados","title":"Criando Prompts Personalizados","text":"<p>Voc\u00ea tem controle total para criar seus pr\u00f3prios prompts:</p>"},{"location":"guides/system-prompts/#exemplo-prompt-minimalista-economia-maxima","title":"Exemplo: Prompt Minimalista (economia m\u00e1xima)","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\nresults = vg.search(\"O que \u00e9 ETP?\")\n\n# Prompt ultra-curto (~15 tokens)\nmeu_prompt = \"Responda usando apenas o contexto. Cite fontes.\"\n\nmessages = results.to_messages(\n    query=\"O que \u00e9 ETP?\",\n    system_prompt=meu_prompt\n)\n\n# Use com seu LLM\nresponse = openai.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=messages\n)\n</code></pre> <p>Economia: ~80 tokens a menos que <code>default</code> = ~$0.80/10.000 requisi\u00e7\u00f5es no GPT-4o.</p>"},{"location":"guides/system-prompts/#exemplo-prompt-para-dominio-especifico","title":"Exemplo: Prompt para Dom\u00ednio Espec\u00edfico","text":"<pre><code># Prompt especializado em preg\u00f5es (~100 tokens)\nprompt_pregao = \"\"\"Voc\u00ea \u00e9 um pregoeiro experiente.\n\nRegras:\n1. Responda apenas sobre preg\u00e3o eletr\u00f4nico e presencial\n2. Cite artigos da Lei 14.133/2021 e Lei 10.520/2002\n3. Se a pergunta n\u00e3o for sobre preg\u00e3o, diga que n\u00e3o pode ajudar\n4. Formato: resposta direta + cita\u00e7\u00e3o legal\"\"\"\n\nmessages = results.to_messages(\n    query=\"Qual o prazo para impugna\u00e7\u00e3o no preg\u00e3o?\",\n    system_prompt=prompt_pregao\n)\n</code></pre>"},{"location":"guides/system-prompts/#exemplo-prompt-bilingue","title":"Exemplo: Prompt Bil\u00edngue","text":"<pre><code># Para sistemas que precisam responder em ingl\u00eas\nprompt_en = \"\"\"You are a legal assistant specialized in Brazilian public procurement law.\n\nInstructions:\n1. Answer in English\n2. Use only the provided context\n3. Cite sources as [Law X, Art. Y]\n4. Explain Brazilian legal terms when needed\"\"\"\n\nmessages = results.to_messages(\n    query=\"What is ETP in Brazilian procurement?\",\n    system_prompt=prompt_en\n)\n</code></pre>"},{"location":"guides/system-prompts/#dicas-para-otimizar-custos","title":"Dicas para Otimizar Custos","text":""},{"location":"guides/system-prompts/#1-escolha-o-prompt-certo","title":"1. Escolha o Prompt Certo","text":"Cen\u00e1rio Prompt Recomendado Chatbot de alto volume <code>concise</code> ou personalizado m\u00ednimo Portal de transpar\u00eancia <code>chatbot</code> Uso interno <code>default</code> Parecer jur\u00eddico <code>detailed</code>"},{"location":"guides/system-prompts/#2-reduza-o-contexto-top_k","title":"2. Reduza o Contexto (top_k)","text":"<pre><code># Menos chunks = menos tokens = menor custo\nresults = vg.search(\"query\", top_k=3)  # ao inv\u00e9s de 5\n</code></pre> top_k Tokens contexto (aprox) Redu\u00e7\u00e3o 5 ~1500 tokens baseline 3 ~900 tokens -40% 2 ~600 tokens -60%"},{"location":"guides/system-prompts/#3-use-modelos-mais-baratos-para-casos-simples","title":"3. Use Modelos Mais Baratos para Casos Simples","text":"<pre><code># Perguntas simples \u2192 GPT-4o-mini ou Gemini Flash\nif is_simple_query(query):\n    model = \"gpt-4o-mini\"  # 17x mais barato que GPT-4o\nelse:\n    model = \"gpt-4o\"\n</code></pre>"},{"location":"guides/system-prompts/#4-monitore-tokens-consumidos","title":"4. Monitore Tokens Consumidos","text":"<pre><code>import tiktoken\n\ndef count_tokens(messages, model=\"gpt-4o\"):\n    enc = tiktoken.encoding_for_model(model)\n    return sum(len(enc.encode(m[\"content\"])) for m in messages)\n\nmessages = results.to_messages(\"O que \u00e9 ETP?\")\ntokens = count_tokens(messages)\nprint(f\"Esta requisi\u00e7\u00e3o consumir\u00e1 ~{tokens} tokens de input\")\n</code></pre>"},{"location":"guides/system-prompts/#referencia-rapida","title":"Refer\u00eancia R\u00e1pida","text":"<pre><code>from vectorgov import VectorGov\n\nvg = VectorGov(api_key=\"vg_xxx\")\n\n# Ver prompts dispon\u00edveis\nprint(vg.available_prompts)\n# ['default', 'concise', 'detailed', 'chatbot']\n\n# Ver conte\u00fado de um prompt\nprint(vg.get_system_prompt(\"concise\"))\n\n# Usar prompt pr\u00e9-definido\nmessages = results.to_messages(\n    query=\"...\",\n    system_prompt=vg.get_system_prompt(\"detailed\")\n)\n\n# Usar prompt personalizado\nmessages = results.to_messages(\n    query=\"...\",\n    system_prompt=\"Seu prompt aqui...\"\n)\n\n# Sem system prompt (s\u00f3 contexto + pergunta)\nmessages = results.to_messages(\n    query=\"...\",\n    system_prompt=\"\"\n)\n</code></pre>"},{"location":"guides/system-prompts/#faq","title":"FAQ","text":""},{"location":"guides/system-prompts/#o-vectorgov-cobra-pelos-tokens-do-prompt","title":"O VectorGov cobra pelos tokens do prompt?","text":"<p>N\u00e3o. O VectorGov cobra apenas pela busca sem\u00e2ntica. Os tokens do prompt s\u00e3o processados pelo seu LLM (OpenAI, Gemini, Claude), e voc\u00ea paga diretamente para eles.</p>"},{"location":"guides/system-prompts/#posso-usar-o-vectorgov-sem-system-prompt","title":"Posso usar o VectorGov sem system prompt?","text":"<p>Sim. Passe <code>system_prompt=\"\"</code> e o LLM receber\u00e1 apenas o contexto e a pergunta. \u00datil quando voc\u00ea j\u00e1 tem instru\u00e7\u00f5es no n\u00edvel da aplica\u00e7\u00e3o.</p>"},{"location":"guides/system-prompts/#qual-o-tamanho-maximo-do-prompt-personalizado","title":"Qual o tamanho m\u00e1ximo do prompt personalizado?","text":"<p>N\u00e3o h\u00e1 limite no SDK. O limite \u00e9 do seu LLM (geralmente 4K-128K tokens de contexto total).</p>"},{"location":"guides/system-prompts/#o-prompt-afeta-a-qualidade-da-resposta","title":"O prompt afeta a qualidade da resposta?","text":"<p>Sim, significativamente. Prompts mais detalhados geralmente produzem respostas melhores, mas com custo maior. Teste diferentes prompts para encontrar o equil\u00edbrio ideal para seu caso de uso.</p>"},{"location":"guides/system-prompts/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>Modos de Busca - Controle lat\u00eancia vs precis\u00e3o</li> <li>Integra\u00e7\u00e3o com LLMs - Exemplos completos</li> <li>Refer\u00eancia da API - Documenta\u00e7\u00e3o t\u00e9cnica</li> </ul>"}]}